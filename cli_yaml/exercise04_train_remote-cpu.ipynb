{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise04 : Train on Remote CPU Virtual Machine\n",
        "\n",
        "Now we run our previous sample (see \"[Exercise03 : Just Train in Your Working Machine](./exercise03_train_simple.ipynb)\") on remote virtual machine with CPU utilized.<br>\n",
        "You can also run remote training on your favorite docker images.\n",
        "\n",
        "*back to [index](https://github.com/tsmatz/azureml-tutorial/)*"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variable's Setting\n",
        "\n",
        "Replace below's branket's string and set the required variables."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "my_resource_group = \"{AML-RESOURCE-GROUP-NAME}\"\n",
        "my_workspace = \"{AML-WORSPACE-NAME}\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save your training script as file (train.py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create ```scirpt``` directory and save Python script as ```./script/train.py```."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "script_folder = './script'\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile script/train.py\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import argparse\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "FLAGS = None\n",
        "batch_size = 100\n",
        "\n",
        "#\n",
        "# define functions for Estimator\n",
        "#\n",
        "\n",
        "def _my_input_fn(filepath, num_epochs):\n",
        "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
        "    # label - digit (0, 1, ..., 9)\n",
        "    data_queue = tf.train.string_input_producer(\n",
        "        [filepath],\n",
        "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
        "    data_reader = tf.TFRecordReader()\n",
        "    _, serialized_exam = data_reader.read(data_queue)\n",
        "    data_exam = tf.parse_single_example(\n",
        "        serialized_exam,\n",
        "        features={\n",
        "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
        "            'label': tf.FixedLenFeature([], tf.int64)\n",
        "        })\n",
        "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
        "    data_image.set_shape([784])\n",
        "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
        "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
        "    data_batch_image, data_batch_label = tf.train.batch(\n",
        "        [data_image, data_label],\n",
        "        batch_size=batch_size)\n",
        "    return {'inputs': data_batch_image}, data_batch_label\n",
        "\n",
        "def _get_input_fn(filepath, num_epochs):\n",
        "    return lambda: _my_input_fn(filepath, num_epochs)\n",
        "\n",
        "def _my_model_fn(features, labels, mode):\n",
        "    # with tf.device(...): # You can set device if using GPUs\n",
        "\n",
        "    # define network and inference\n",
        "    # (simple 2 fully connected hidden layer : 784->128->64->10)\n",
        "    with tf.name_scope('hidden1'):\n",
        "        weights = tf.Variable(\n",
        "            tf.truncated_normal(\n",
        "                [784, FLAGS.first_layer],\n",
        "                stddev=1.0 / math.sqrt(float(784))),\n",
        "            name='weights')\n",
        "        biases = tf.Variable(\n",
        "            tf.zeros([FLAGS.first_layer]),\n",
        "            name='biases')\n",
        "        hidden1 = tf.nn.relu(tf.matmul(features['inputs'], weights) + biases)\n",
        "    with tf.name_scope('hidden2'):\n",
        "        weights = tf.Variable(\n",
        "            tf.truncated_normal(\n",
        "                [FLAGS.first_layer, FLAGS.second_layer],\n",
        "                stddev=1.0 / math.sqrt(float(FLAGS.first_layer))),\n",
        "            name='weights')\n",
        "        biases = tf.Variable(\n",
        "            tf.zeros([FLAGS.second_layer]),\n",
        "            name='biases')\n",
        "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
        "    with tf.name_scope('softmax_linear'):\n",
        "        weights = tf.Variable(\n",
        "            tf.truncated_normal(\n",
        "                [FLAGS.second_layer, 10],\n",
        "                stddev=1.0 / math.sqrt(float(FLAGS.second_layer))),\n",
        "        name='weights')\n",
        "        biases = tf.Variable(\n",
        "            tf.zeros([10]),\n",
        "            name='biases')\n",
        "        logits = tf.matmul(hidden2, weights) + biases\n",
        " \n",
        "    # compute evaluation matrix\n",
        "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
        "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
        "        label_indices = tf.cast(labels, tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(label_indices, predicted_indices)\n",
        "        tf.summary.scalar('accuracy', accuracy[1]) # output to TensorBoard\n",
        " \n",
        "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
        "            labels=labels,\n",
        "            logits=logits)\n",
        " \n",
        "    # define operations\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        #global_step = tf.train.create_global_step()\n",
        "        #global_step = tf.contrib.framework.get_or_create_global_step()\n",
        "        global_step = tf.train.get_or_create_global_step()        \n",
        "        optimizer = tf.train.GradientDescentOptimizer(\n",
        "            learning_rate=FLAGS.learning_rate)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=global_step)\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode,\n",
        "            loss=loss,\n",
        "            train_op=train_op)\n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "        eval_metric_ops = {\n",
        "            'accuracy': accuracy\n",
        "        }\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metric_ops)\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
        "        predictions = {\n",
        "            'classes': predicted_indices,\n",
        "            'probabilities': probabilities\n",
        "        }\n",
        "        export_outputs = {\n",
        "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
        "        }\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode,\n",
        "            predictions=predictions,\n",
        "            export_outputs=export_outputs)\n",
        "\n",
        "def _my_serving_input_fn():\n",
        "    inputs = {'inputs': tf.placeholder(tf.float32, [None, 784])}\n",
        "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
        "\n",
        "#\n",
        "# Main\n",
        "#\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    '--data_folder',\n",
        "    type=str,\n",
        "    default='./data',\n",
        "    help='Folder path for input data')\n",
        "parser.add_argument(\n",
        "    '--chkpoint_folder',\n",
        "    type=str,\n",
        "    default='./logs',  # AML experiments logs folder\n",
        "    help='Folder path for checkpoint files')\n",
        "parser.add_argument(\n",
        "    '--model_folder',\n",
        "    type=str,\n",
        "    default='./outputs',  # AML experiments outputs folder\n",
        "    help='Folder path for model output')\n",
        "parser.add_argument(\n",
        "    '--learning_rate',\n",
        "    type=float,\n",
        "    default='0.07',\n",
        "    help='Learning Rate')\n",
        "parser.add_argument(\n",
        "    '--first_layer',\n",
        "    type=int,\n",
        "    default='128',\n",
        "    help='Neuron number for the first hidden layer')\n",
        "parser.add_argument(\n",
        "    '--second_layer',\n",
        "    type=int,\n",
        "    default='64',\n",
        "    help='Neuron number for the second hidden layer')\n",
        "FLAGS, unparsed = parser.parse_known_args()\n",
        "\n",
        "# clean checkpoint and model folder if exists\n",
        "if os.path.exists(FLAGS.chkpoint_folder) :\n",
        "    for file_name in os.listdir(FLAGS.chkpoint_folder):\n",
        "        file_path = os.path.join(FLAGS.chkpoint_folder, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            os.remove(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "if os.path.exists(FLAGS.model_folder) :\n",
        "    for file_name in os.listdir(FLAGS.model_folder):\n",
        "        file_path = os.path.join(FLAGS.model_folder, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            os.remove(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "\n",
        "# read TF_CONFIG\n",
        "run_config = tf.estimator.RunConfig()\n",
        "\n",
        "# create Estimator\n",
        "mnist_fullyconnected_classifier = tf.estimator.Estimator(\n",
        "    model_fn=_my_model_fn,\n",
        "    model_dir=FLAGS.chkpoint_folder,\n",
        "    config=run_config)\n",
        "train_spec = tf.estimator.TrainSpec(\n",
        "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'train.tfrecords'), 2),\n",
        "    max_steps=60000 * 2 / batch_size)\n",
        "eval_spec = tf.estimator.EvalSpec(\n",
        "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
        "    steps=10000 * 1 / batch_size,\n",
        "    start_delay_secs=0)\n",
        "\n",
        "# run !\n",
        "tf.estimator.train_and_evaluate(\n",
        "    mnist_fullyconnected_classifier,\n",
        "    train_spec,\n",
        "    eval_spec\n",
        ")\n",
        "\n",
        "# save model and variables\n",
        "model_dir = mnist_fullyconnected_classifier.export_savedmodel(\n",
        "    export_dir_base = FLAGS.model_folder,\n",
        "    serving_input_receiver_fn = _my_serving_input_fn)\n",
        "print('current working directory is ', os.getcwd())\n",
        "print('model is saved ', model_dir)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train on remote VM\n",
        "\n",
        "Now let's start to integrate with AML and automate training on remote virtual machine."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 : Create new remote virtual machine\n",
        "\n",
        "Create your new reomte virtual machine with **CPU**.<br>\n",
        "Before starting, **please check the following**.\n",
        "\n",
        "- Make sure that the following size (in the following script, ```Standard_D2_v2```) is supported in the location (in which AML workspace resides).\n",
        "- You should have quota for ML CPU VM in your Azure subscription. If you don't have, please request quota in Azure Portal.\n",
        "\n",
        "By setting 0 in ```--min-instances```, the node will be terminated if it's inactive. (You can save money.)    \n",
        "\n",
        "> Note : You can also attach an existing virtual machine (bring your own compute resource) as a compute target."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml compute create --name myvmcpu \\\n",
        "  --resource-group $my_resource_group \\\n",
        "  --workspace-name $my_workspace \\\n",
        "  --type amlcompute \\\n",
        "  --min-instances 0 \\\n",
        "  --max-instances 1 \\\n",
        "  --size Standard_D2_v2  # or Standard_NC6"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 : Submit training job"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submit a training job with above compute and environment.\n",
        "\n",
        "In this example, I use the registered data asset  (train.tfrecords, test.tfrecords) named ```mnist_tfrecords_data``` to mount in your compute target. (Run \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for data preparation.)\n",
        "In order to use data asset in AML, set ```azureml:{DATA_NAME}:{DATA_VERSION}``` or ```azureml:{DATA_NAME}@latest``` for the latest version of assets as follows."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 04_mnist_train_job_cpu.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
        "code: script\n",
        "command: >-\n",
        "  python train.py\n",
        "  --data_folder ${{inputs.mnist_tf}}\n",
        "inputs:\n",
        "  mnist_tf:\n",
        "    type: uri_folder\n",
        "    path: azureml:mnist_tfrecords_data@latest\n",
        "environment: \n",
        "  image: mcr.microsoft.com/azureml/tensorflow-1.15-ubuntu18.04-py37-cpu-inference:20220516.v3\n",
        "compute: azureml:myvmcpu\n",
        "display_name: tf_remote_experiment_cpu\n",
        "experiment_name: tf_remote_experiment_cpu\n",
        "description: This is example"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's submit a job with AML CLI.<br>\n",
        "See the progress and results in [AML Studio](https://ml.azure.com/) experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml job create --file 04_mnist_train_job_cpu.yml \\\n",
        "  --resource-group $my_resource_group \\\n",
        "  --workspace-name $my_workspace"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please wait until the job is completed.\n",
        "\n",
        "You can show the progress and result with [AML studio UI](https://ml.azure.com/) (see \"Jobs\" pane) or with the following CLI command.<br>\n",
        "(**Replace ```nifty_tree_cftvbh77f7``` with your generated job name**. For job name, see above output.)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "job_name = \"nifty_tree_cftvbh77f7\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml job show --name $job_name \\\n",
        "  --resource-group $my_resource_group \\\n",
        "  --workspace-name $my_workspace"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 : Download results and evaluate\n",
        "\n",
        "Now let's check the generated model in local computer.\n",
        "\n",
        "Go to [Azure ML studio UI](https://ml.azure.com/).<br>\n",
        "You can then see the saved model in outputs directory.\n",
        "\n",
        "![Saved Outputs](https://tsmatz.github.io/images/github/azure-ml-tensorflow-complete-sample/20220225_Experiment_Outputs.jpg)\n",
        "\n",
        "By running the following ```az ml job download``` command, the logs and outputs are downloaded in local computer.<br>\n",
        "The logs are saved in ```artifacts/logs``` and outputs are in ```artifacts/outputs```."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml job download --name $job_name \\\n",
        "  --resource-group $my_resource_group \\\n",
        "  --workspace-name $my_workspace"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now check the downloaded result.<br>\n",
        "(**Replace ```1654560514``` with your generated model name**.)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "MODEL_NAME = \"1654560514\"\n",
        "\n",
        "# Read data by tensor\n",
        "tfdata = tf.data.TFRecordDataset('./data/test.tfrecords')\n",
        "iterator = tf.compat.v1.data.make_one_shot_iterator(tfdata)\n",
        "data_org = iterator.get_next()\n",
        "data_exam = tf.parse_single_example(\n",
        "    data_org,\n",
        "    features={\n",
        "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
        "        'label': tf.FixedLenFeature([], tf.int64)\n",
        "    })\n",
        "data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
        "data_image.set_shape([784])\n",
        "data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
        "data_label = tf.cast(data_exam['label'], tf.int32)\n",
        "\n",
        "# Run tensor and generate data\n",
        "with tf.Session() as sess:\n",
        "    image_arr = []\n",
        "    label_arr = []\n",
        "    for i in range(3):\n",
        "        image, label = sess.run([data_image, data_label])\n",
        "        image_arr.append(image)\n",
        "        label_arr.append(label)\n",
        "\n",
        "# Predict\n",
        "pred_fn = tf.contrib.predictor.from_saved_model('./artifacts/outputs/{}'.format(MODEL_NAME))\n",
        "pred = pred_fn({'inputs': image_arr})\n",
        "\n",
        "print('Predicted: ', pred['classes'].tolist())\n",
        "print('Actual   : ', label_arr)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 : Register Model\n",
        "\n",
        "Now upload (register) the downloaded model into AML model management.<br>\n",
        "(**Replace the following ```1654560514``` with your job name and model name**.)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./artifacts/outputs/1654560514 ./generated_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml model create --name mnist_model_test \\\n",
        "  --version 1 \\\n",
        "  --path ./generated_model \\\n",
        "  --resource-group $my_resource_group \\\n",
        "  --workspace-name $my_workspace"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 : Remove AML compute\n",
        "\n",
        "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.<br>\n",
        "But if you want to clean up, please run as follows."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml compute delete --name myvmcpu \\\n",
        "  --resource-group $my_resource_group \\\n",
        "  --workspace-name $my_workspace \\\n",
        "  --yes"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}