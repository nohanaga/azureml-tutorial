{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise09 : ML Pipeline\n",
    "\n",
    "With AML pipeline, you can create ML workflows for the following purposes.\n",
    "\n",
    "- You can build retraining pipeline for MLOps integration.\n",
    "- You can build batch-scoring pipeline instead of real-time scoring in \"[Exercise08 : Publish as a Web Service](./exercise08_publish_model.ipynb)\".\n",
    "\n",
    "ML pipeline can be invoked by the following methods. \n",
    "\n",
    "- Time-based schedule invocation\n",
    "- On-demand invocation by the published endpoint (REST)\n",
    "- Trigger-based invocation, such as, file change or other combined events (with Azure Event Grid, Azure Logic Apps, etc)\n",
    "\n",
    "In this exercise, we create a training pipeline for MLOps integration. (See [here](https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/ai/mlops-python) for the reference architecture integrating with CI/CD tools.)\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Variable's Setting\n",
    "\n",
    "Replace below's branket's string and set the required variables.\n",
    "\n",
    "Using ```az login --service-principal``` command, you would be able to involve ML pipeline in CI/CD utilities, such as, in GitHub actions, without login UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resource_group = \"{AML-RESOURCE-GROUP-NAME}\"\n",
    "my_workspace = \"{AML-WORSPACE-NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create compute\n",
    "\n",
    "Create your new AML compute for running pipeline.\n",
    "\n",
    "When the pipeline is invoked, the compute will be started. When the pipeline is completed, this compute will be automatically scaled down to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml compute' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "{\n",
      "  \"id\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AzureML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/computes/mycluster01\",\n",
      "  \"idle_time_before_scale_down\": 120,\n",
      "  \"location\": \"eastus\",\n",
      "  \"max_instances\": 1,\n",
      "  \"min_instances\": 0,\n",
      "  \"name\": \"mycluster01\",\n",
      "  \"network_settings\": {},\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"AzureML-rg\",\n",
      "  \"size\": \"STANDARD_D2_V2\",\n",
      "  \"ssh_public_access_enabled\": true,\n",
      "  \"tier\": \"dedicated\",\n",
      "  \"type\": \"amlcompute\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute create --name mycluster01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --type amlcompute \\\n",
    "  --min-instances 0 \\\n",
    "  --max-instances 1 \\\n",
    "  --size Standard_D2_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, I create a pipeline for model training, evaluation, and model registration.<br>\n",
    "Each source code will then be saved as follows.\n",
    "\n",
    "- training script ```./pipeline_script/train.py```\n",
    "- evaluation script ```./pipeline_script/evaluate.py```\n",
    "- registration script ```./pipeline_script/register_model.py```\n",
    "\n",
    "Model name (sub folder name in model dir) is set in model info file (JSON text), which is passed into the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './pipeline_script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline_script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline_script/train.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None\n",
    "batch_size = 100\n",
    "\n",
    "#\n",
    "# Define functions for Estimator\n",
    "#\n",
    "\n",
    "def _my_input_fn(filepath, num_epochs):\n",
    "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
    "    # label - digit (0, 1, ..., 9)\n",
    "    data_queue = tf.train.string_input_producer(\n",
    "        [filepath],\n",
    "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
    "    data_reader = tf.TFRecordReader()\n",
    "    _, serialized_exam = data_reader.read(data_queue)\n",
    "    data_exam = tf.parse_single_example(\n",
    "        serialized_exam,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "    data_image.set_shape([784])\n",
    "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "    data_batch_image, data_batch_label = tf.train.batch(\n",
    "        [data_image, data_label],\n",
    "        batch_size=batch_size)\n",
    "    return {'inputs': data_batch_image}, data_batch_label\n",
    "\n",
    "def _get_input_fn(filepath, num_epochs):\n",
    "    return lambda: _my_input_fn(filepath, num_epochs)\n",
    "\n",
    "def _my_model_fn(features, labels, mode):\n",
    "    # with tf.device(...): # You can set device if using GPUs\n",
    "\n",
    "    # define network and inference\n",
    "    # (simple 2 fully connected hidden layer : 784->128->64->10)\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [784, FLAGS.first_layer],\n",
    "                stddev=1.0 / math.sqrt(float(784))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.first_layer]),\n",
    "            name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(features['inputs'], weights) + biases)\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.first_layer, FLAGS.second_layer],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.first_layer))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.second_layer]),\n",
    "            name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.second_layer, 10],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.second_layer))),\n",
    "        name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([10]),\n",
    "            name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    " \n",
    "    # compute evaluation matrix\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        label_indices = tf.cast(labels, tf.int32)\n",
    "        accuracy = tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "        tf.summary.scalar('accuracy', accuracy[1]) # output to TensorBoard\n",
    " \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels,\n",
    "            logits=logits)\n",
    " \n",
    "    # define operations\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #global_step = tf.train.create_global_step()\n",
    "        #global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        global_step = tf.train.get_or_create_global_step()        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=FLAGS.learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "        predictions = {\n",
    "            'classes': predicted_indices,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            predictions=predictions,\n",
    "            export_outputs=export_outputs)\n",
    "\n",
    "def _my_serving_input_fn():\n",
    "    inputs = {'inputs': tf.placeholder(tf.float32, [None, 784])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "_my_evaluation_input_fn = (tf.estimator.experimental.build_raw_supervised_input_receiver_fn(\n",
    "    {'inputs': tf.placeholder(dtype=tf.float32, shape=[None, 784])},\n",
    "    tf.placeholder(dtype=tf.int32, shape=[None])))\n",
    "\n",
    "#\n",
    "# Main\n",
    "#\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data_folder',\n",
    "    type=str,\n",
    "    default='./data',\n",
    "    help='Folder path for input data')\n",
    "parser.add_argument(\n",
    "    '--chkpoint_folder',\n",
    "    type=str,\n",
    "    default='./logs',  # AML experiments logs folder\n",
    "    help='Folder path for checkpoint files')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./outputs',  # AML experiments outputs folder\n",
    "    help='Folder path for model output')\n",
    "parser.add_argument(\n",
    "    '--model_info',\n",
    "    type=str,\n",
    "    help='JSON file path for saving model information')\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default='0.07',\n",
    "    help='Learning Rate')\n",
    "parser.add_argument(\n",
    "    '--first_layer',\n",
    "    type=int,\n",
    "    default='128',\n",
    "    help='Neuron number for the first hidden layer')\n",
    "parser.add_argument(\n",
    "    '--second_layer',\n",
    "    type=int,\n",
    "    default='64',\n",
    "    help='Neuron number for the second hidden layer')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# Clean checkpoint and model folder if exists\n",
    "if os.path.exists(FLAGS.chkpoint_folder) :\n",
    "    for file_name in os.listdir(FLAGS.chkpoint_folder):\n",
    "        file_path = os.path.join(FLAGS.chkpoint_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "if os.path.exists(FLAGS.model_folder) :\n",
    "    for file_name in os.listdir(FLAGS.model_folder):\n",
    "        file_path = os.path.join(FLAGS.model_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "# Read TF_CONFIG\n",
    "run_config = tf.estimator.RunConfig()\n",
    "\n",
    "# Create Estimator\n",
    "mnist_fullyconnected_classifier = tf.estimator.Estimator(\n",
    "    model_fn=_my_model_fn,\n",
    "    model_dir=FLAGS.chkpoint_folder,\n",
    "    config=run_config)\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'train.tfrecords'), 2),\n",
    "    max_steps=60000 * 2 / batch_size)\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
    "    steps=10000 * 1 / batch_size,\n",
    "    start_delay_secs=0)\n",
    "\n",
    "# Run training !\n",
    "tf.estimator.train_and_evaluate(\n",
    "    mnist_fullyconnected_classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "# Save model and parameters\n",
    "model_folder = mnist_fullyconnected_classifier.experimental_export_all_saved_models(\n",
    "    export_dir_base=FLAGS.model_folder,\n",
    "    input_receiver_fn_map={\n",
    "        tf.estimator.ModeKeys.EVAL: _my_evaluation_input_fn,\n",
    "        tf.estimator.ModeKeys.PREDICT: _my_serving_input_fn\n",
    "    })\n",
    "print('current working directory is ', os.getcwd())\n",
    "print('model is saved ', model_folder)\n",
    "\n",
    "# Save model info\n",
    "model_folder_name = os.path.basename(model_folder.decode(\"utf-8\"))\n",
    "model_info_dict = {'model_folder_name' : model_folder_name}\n",
    "model_info_json = json.dumps(model_info_dict)\n",
    "f = open(FLAGS.model_info,\"w\")\n",
    "f.write(model_info_json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline_script/evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline_script/evaluate.py\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "FLAGS = None\n",
    "batch_size = 100\n",
    "\n",
    "def _my_input_fn(filepath, num_epochs):\n",
    "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
    "    # label - digit (0, 1, ..., 9)\n",
    "    data_queue = tf.train.string_input_producer(\n",
    "        [filepath],\n",
    "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
    "    data_reader = tf.TFRecordReader()\n",
    "    _, serialized_exam = data_reader.read(data_queue)\n",
    "    data_exam = tf.parse_single_example(\n",
    "        serialized_exam,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "    data_image.set_shape([784])\n",
    "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "    data_batch_image, data_batch_label = tf.train.batch(\n",
    "        [data_image, data_label],\n",
    "        batch_size=batch_size)\n",
    "    return {'inputs': data_batch_image}, data_batch_label\n",
    "\n",
    "def _get_input_fn(filepath, num_epochs):\n",
    "    return lambda: _my_input_fn(filepath, num_epochs)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data_folder',\n",
    "    type=str,\n",
    "    default='./data',\n",
    "    help='Folder path for input data')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./model',\n",
    "    help='Folder path for model base dir')\n",
    "parser.add_argument(\n",
    "    '--model_input_info',\n",
    "    type=str,\n",
    "    default='./model_input_info',\n",
    "    help='File path for model evaluation info')\n",
    "parser.add_argument(\n",
    "    '--model_output_info',\n",
    "    type=str,\n",
    "    default='./model_output_info',\n",
    "    help='File path for model registration info')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# Get model folder\n",
    "f = open(FLAGS.model_input_info)\n",
    "model_input_json = json.load(f)\n",
    "model_folder_fullpath = os.path.join(FLAGS.model_folder, model_input_json['model_folder_name'])\n",
    "f.close()\n",
    "\n",
    "# Load model\n",
    "est = tf.contrib.estimator.SavedModelEstimator(model_folder_fullpath)\n",
    "\n",
    "# Evaluate !\n",
    "eval_results = est.evaluate(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
    "    steps=10000 * 1 / batch_size)\n",
    "\n",
    "# Result check\n",
    "# (If it doen't achieve threshold, stop running)\n",
    "if eval_results['metrics/accuracy'] >= 0.92:\n",
    "    # Evaluation Success\n",
    "    print(\n",
    "        \"Evaluation has passed. \"\n",
    "        \"Accuracy: {}, Loss: {}\".format(\n",
    "            eval_results['metrics/accuracy'], eval_results['loss']\n",
    "        )\n",
    "    )\n",
    "    # Save model info\n",
    "    model_info_dict = {\n",
    "        'model_folder_name' : model_input_json['model_folder_name'],\n",
    "        'evaluation' : True\n",
    "    }\n",
    "    model_output_json = json.dumps(model_info_dict)\n",
    "    f = open(FLAGS.model_output_info,\"w\")\n",
    "    f.write(model_output_json)\n",
    "    f.close()\n",
    "\n",
    "else:\n",
    "    # Evaluation Failure\n",
    "    print(\n",
    "        \"Evaluation has failed. \"\n",
    "        \"Accuracy: {}, Loss: {}\".format(\n",
    "            eval_results['metrics/accuracy'], eval_results['loss']\n",
    "        )\n",
    "    )\n",
    "    # Cancel pipeline\n",
    "    run.parent.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline_script/register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline_script/register_model.py\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from azureml.core import Run, Dataset\n",
    "from azureml.core.model import Model\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--model_name',\n",
    "    type=str,\n",
    "    default='mlops-test-model',\n",
    "    help='Model name for registeration')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./model',\n",
    "    help='Folder path for model base dir')\n",
    "parser.add_argument(\n",
    "    '--model_input_info',\n",
    "    type=str,\n",
    "    default='./model_input_info',\n",
    "    help='File path for model info')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "f = open(FLAGS.model_input_info)\n",
    "\n",
    "# Check evaluation result\n",
    "model_input_json = json.load(f)\n",
    "if model_input_json['evaluation']:\n",
    "    # Get model folder\n",
    "    model_folder_fullpath = os.path.join(FLAGS.model_folder, model_input_json['model_folder_name'])\n",
    "\n",
    "    # Register model !\n",
    "    model = Model.register(\n",
    "        workspace=run.experiment.workspace,\n",
    "        model_name=FLAGS.model_name,\n",
    "        model_path=model_folder_fullpath)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XXXXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "> Note : In this example, I also use the registered dataset  (train.tfrecords, test.tfrecords) named ```mnist_tfrecords_dataset``` to mount in your compute target. Run \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for dataset preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 09_training_pipeline_job.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile 09_training_pipeline_job.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\n",
    "type: pipeline\n",
    "display_name: training-pipeline01\n",
    "experiment_name: training-pipeline01\n",
    "inputs:\n",
    "  mnist_tf:\n",
    "    dataset: azureml:mnist_tfrecords_dataset:1\n",
    "jobs:\n",
    "  train-model:\n",
    "    command: >-\n",
    "      python train.py\n",
    "      --data_folder ${{inputs.mnist_tf}}\n",
    "      --model_folder ${{outputs.model_dir}}\n",
    "      --model_info ${{outputs.model_info}}/eval.txt\n",
    "    code:\n",
    "      local_path: pipeline_script\n",
    "    outputs:\n",
    "      model_dir:\n",
    "      model_info:\n",
    "    environment: azureml:AzureML-TensorFlow-1.13-CPU:30\n",
    "    compute: azureml:mycluster01\n",
    "  evaluate-model:\n",
    "    command: >-\n",
    "      python evaluate.py\n",
    "      --data_folder ${{inputs.mnist_tf}}\n",
    "      --model_folder ${{inputs.model_dir}}\n",
    "      --model_input_info ${{inputs.model_info}}/eval.txt\n",
    "      --model_output_info ${{inputs.model_info}}/reg.txt\n",
    "    code:\n",
    "      local_path: pipeline_script\n",
    "    inputs:\n",
    "      model_dir: ${{jobs.train-model.outputs.model_dir}}\n",
    "      model_info: ${{jobs.train-model.outputs.model_info}}\n",
    "    environment: azureml:AzureML-TensorFlow-1.13-CPU:30\n",
    "    compute: azureml:mycluster01\n",
    "  register-model:\n",
    "    command: >-\n",
    "      python register_model.py\n",
    "      --model_name \"mlops-test-model\"\n",
    "      --model_folder ${{inputs.model_dir}}\n",
    "      --model_input_info ${{inputs.model_info}}/reg.txt\n",
    "    code:\n",
    "      local_path: pipeline_script\n",
    "    inputs:\n",
    "      model_dir: ${{jobs.train-model.outputs.model_dir}}\n",
    "      model_info: ${{jobs.train-model.outputs.model_info}}\n",
    "    environment: azureml:AzureML-TensorFlow-1.13-CPU:30\n",
    "    compute: azureml:mycluster01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml job' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "'name', 'display_name', and 'experiment_name' cannot be configured for a child job within a pipeline job. These settings will be ignored.\n",
      "\u001b[32mUploading pipeline_script (0.01 MBs): 100%|█| 12075/12075 [00:00<00:00, 160286.0\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "'name', 'display_name', and 'experiment_name' cannot be configured for a child job within a pipeline job. These settings will be ignored.\n",
      "'name', 'display_name', and 'experiment_name' cannot be configured for a child job within a pipeline job. These settings will be ignored.\n",
      "{\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-02-28T08:54:30.366004+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"display_name\": \"training-pipeline01\",\n",
      "  \"experiment_name\": \"training-pipeline01\",\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AzureML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/775424f8-2e6f-4c43-8f37-d98d152b37f7\",\n",
      "  \"inputs\": {},\n",
      "  \"jobs\": {\n",
      "    \"evaluate-model\": {\n",
      "      \"component\": \"azureml:4551f046-1d62-431f-bf3b-f09b763f7639:1\",\n",
      "      \"compute\": \"azureml:mycluster01\",\n",
      "      \"inputs\": {\n",
      "        \"mnist_tf\": {\n",
      "          \"dataset\": \"azureml:mnist_tfrecords_dataset:1\",\n",
      "          \"mode\": \"ro_mount\"\n",
      "        },\n",
      "        \"model_dir\": \"${{jobs.train-model.outputs.model_dir}}\",\n",
      "        \"model_info\": \"${{jobs.train-model.outputs.model_info}}\"\n",
      "      },\n",
      "      \"outputs\": {},\n",
      "      \"overrides\": {},\n",
      "      \"type\": \"component\"\n",
      "    },\n",
      "    \"register-model\": {\n",
      "      \"component\": \"azureml:f3a76b61-6235-4291-a415-f1a34ee937cf:1\",\n",
      "      \"compute\": \"azureml:mycluster01\",\n",
      "      \"inputs\": {\n",
      "        \"model_dir\": \"${{jobs.train-model.outputs.model_dir}}\",\n",
      "        \"model_info\": \"${{jobs.train-model.outputs.model_info}}\"\n",
      "      },\n",
      "      \"outputs\": {},\n",
      "      \"overrides\": {},\n",
      "      \"type\": \"component\"\n",
      "    },\n",
      "    \"train-model\": {\n",
      "      \"component\": \"azureml:83f5bed4-ad5d-43f7-a266-baa1fd673335:1\",\n",
      "      \"compute\": \"azureml:mycluster01\",\n",
      "      \"inputs\": {\n",
      "        \"mnist_tf\": {\n",
      "          \"dataset\": \"azureml:mnist_tfrecords_dataset:1\",\n",
      "          \"mode\": \"ro_mount\"\n",
      "        }\n",
      "      },\n",
      "      \"outputs\": {\n",
      "        \"model_dir\": {\n",
      "          \"mode\": \"rw_mount\"\n",
      "        },\n",
      "        \"model_info\": {\n",
      "          \"mode\": \"rw_mount\"\n",
      "        }\n",
      "      },\n",
      "      \"overrides\": {},\n",
      "      \"type\": \"component\"\n",
      "    }\n",
      "  },\n",
      "  \"name\": \"775424f8-2e6f-4c43-8f37-d98d152b37f7\",\n",
      "  \"outputs\": {},\n",
      "  \"properties\": {\n",
      "    \"azureml.continue_on_step_failure\": \"False\",\n",
      "    \"azureml.parameters\": \"{}\",\n",
      "    \"azureml.pipelineComponent\": \"pipelinerun\",\n",
      "    \"azureml.runsource\": \"azureml.PipelineRun\",\n",
      "    \"runSource\": \"MFE\",\n",
      "    \"runType\": \"HTTP\"\n",
      "  },\n",
      "  \"resourceGroup\": \"AzureML-rg\",\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/775424f8-2e6f-4c43-8f37-d98d152b37f7?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/AzureML-rg/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "      \"job_service_type\": \"Studio\"\n",
      "    },\n",
      "    \"Tracking\": {\n",
      "      \"endpoint\": \"azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AzureML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01?\",\n",
      "      \"job_service_type\": \"Tracking\"\n",
      "    }\n",
      "  },\n",
      "  \"settings\": {},\n",
      "  \"status\": \"Preparing\",\n",
      "  \"tags\": {\n",
      "    \"azureml.Designer\": \"true\"\n",
      "  },\n",
      "  \"type\": \"pipeline\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job create --file 09_training_pipeline_job.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Train Model is ready to be created [ef6019bf]Step Evaluate Model is ready to be created [91e50394]\n",
      "\n",
      "Step Register Model is ready to be created [1f84f98e]\n",
      "Created step Train Model [ef6019bf][d036f40e-f502-4079-9b24-0f5c2f7233d1], (This step will run and generate new outputs)Created step Evaluate Model [91e50394][bb9ed118-8e70-4a60-b20e-164756001f0c], (This step will run and generate new outputs)\n",
      "\n",
      "Created step Register Model [1f84f98e][de7e773a-3c6e-4365-a0be-f9ec4915df2e], (This step will run and generate new outputs)\n"
     ]
    }
   ],
   "source": [
    "# XXXXXXXXXXXX publish ってどうやれば良いの？？？\n",
    "from azureml.pipeline.core import Pipeline\n",
    "import uuid\n",
    "\n",
    "train_pipeline = Pipeline(workspace=ws, steps=[train_step, eval_step, reg_step])\n",
    "train_pipeline._set_experiment_name\n",
    "train_pipeline.validate()\n",
    "published_pipeline = train_pipeline.publish(\n",
    "    name=\"training-pipeline01\",\n",
    "    description=\"Model training/retraining pipeline\",\n",
    "    version=str(uuid.uuid4()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go to [AML studio UI](https://ml.azure.com/) and you can then visually see pipeline graph. (See the following screenshot.)\n",
    "\n",
    "![pipeline graph](https://tsmatz.files.wordpress.com/2021/10/20211027_ml_pipeline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When integrating with CI/CD tools, you can submit a new run of this publised pipeline using REST endpoint on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://eastus.api.azureml.ms/pipelines/v1.0/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/TEST20211027/providers/Microsoft.MachineLearningServices/workspaces/ws02/PipelineRuns/PipelineSubmit/10121bb5-8b8b-4696-8225-efa5cb7efa73'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See endpoint url\n",
    "published_pipeline.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's submit a new run using Python AML SDK.\n",
    "See the progress and results in [AML studio UI](https://ml.azure.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineRun e0d5c0fd-9240-4a2b-bfde-3ec1cbe0a68b\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/e0d5c0fd-9240-4a2b-bfde-3ec1cbe0a68b?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/TEST20211027/workspaces/ws02&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "exp = Experiment(workspace=ws, name='pipeline_experiment01')\n",
    "pipeline_run = exp.submit(published_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Remove Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cluster (nodes) and remove from AML workspace\n",
    "mycompute = AmlCompute(workspace=ws, name='mycluster01')\n",
    "mycompute.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XXXXXXXXXXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 09_training_pipeline_job2.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile 09_training_pipeline_job2.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\n",
    "type: pipeline\n",
    "display_name: training-pipeline02\n",
    "experiment_name: training-pipeline02\n",
    "inputs:\n",
    "  mnist_tf:\n",
    "    dataset: azureml:mnist_tfrecords_dataset:1\n",
    "jobs:\n",
    "  train-model:\n",
    "    command: >-\n",
    "      python train.py\n",
    "      --data_folder ${{inputs.mnist_tf}}\n",
    "      --model_folder ${{outputs.model_dir}}\n",
    "      --model_info ${{outputs.model_info}}/eval.txt\n",
    "    code:\n",
    "      local_path: pipeline_script\n",
    "    outputs:\n",
    "      model_dir:\n",
    "      model_info:\n",
    "    environment: azureml:AzureML-TensorFlow-1.13-CPU:30\n",
    "    compute: azureml:mycluster01\n",
    "  evaluate-model:\n",
    "    command: >-\n",
    "      python evaluate.py\n",
    "      --data_folder ${{inputs.mnist_tf}}\n",
    "      --model_folder ${{inputs.model_dir}}\n",
    "      --model_input_info ${{inputs.model_info}}/eval.txt\n",
    "      --model_output_info ${{inputs.model_info}}/reg.txt\n",
    "    code:\n",
    "      local_path: pipeline_script\n",
    "    inputs:\n",
    "      model_dir: ${{jobs.train-model.outputs.model_dir}}\n",
    "      model_info: ${{jobs.train-model.outputs.model_info}}\n",
    "    environment: azureml:AzureML-TensorFlow-1.13-CPU:30\n",
    "    compute: azureml:mycluster01\n",
    "  register-model:\n",
    "    command: >-\n",
    "      python register_model.py\n",
    "      --model_name \"mlops-test-model\"\n",
    "      --model_folder ${{inputs.model_dir}}\n",
    "      --model_input_info ${{inputs.model_info}}/reg.txt\n",
    "    code:\n",
    "      local_path: pipeline_script\n",
    "    inputs:\n",
    "      model_dir: ${{jobs.train-model.outputs.model_dir}}\n",
    "      model_info: ${{jobs.train-model.outputs.model_info}}\n",
    "    environment: azureml:AzureML-TensorFlow-1.13-CPU:30\n",
    "    compute: azureml:mycluster01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml job create --file 09_training_pipeline_job2.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
