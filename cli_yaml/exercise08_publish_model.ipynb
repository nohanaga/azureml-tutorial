{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise08 : Publish as a Web Service\n",
    "\n",
    "Finally we publish our model as a web service.\n",
    "\n",
    "Before running this code, **complete the model registration in \"[Exercise04 : Train on Remote GPU Virtual Machine](./exercise04_train_remote.ipynb)\"**.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable's Setting\n",
    "\n",
    "Replace below's branket's string and set the required variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resource_group = \"{AML-RESOURCE-GROUP-NAME}\"\n",
    "my_workspace = \"{AML-WORSPACE-NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create entry script (.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deploy as web service, first we generate the following scoring code.<br>\n",
    "This entry script in AML should include both ```init()``` and ```run()```.\n",
    "\n",
    "> Note : The serving compute (VM) provides [managed identity endpoint](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/how-to-use-vm-token). (Your script can use both system-assigned identity and user-assigned identity.) Your script can then get the access permissions for Azure resources without providing secure information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global pred_fn\n",
    "    ## model_path = Model.get_model_path(model_name='mnist_model_test')\n",
    "    model_path = os.path.join(\n",
    "        os.getenv(\"AZUREML_MODEL_DIR\"), \"generated_model\"\n",
    "    )\n",
    "    pred_fn = tf.contrib.predictor.from_saved_model(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "       data = json.loads(raw_data)['data']\n",
    "       result = pred_fn({'inputs': data})\n",
    "       return result['classes'].tolist()\n",
    "    except Exception as e:\n",
    "       result = str(e)\n",
    "       return 'Internal Exception : ' + result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a managed endpoint\n",
    "\n",
    "There exist **endpoint** and **deployment** in deployment topology in managed online endpoint.<br>\n",
    "You can run multiple deployments in a single endpoint, and allocate appropriate traffic for these multiple deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a managed endpoint for deployment target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 08_managed_endpoint.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile 08_managed_endpoint.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineEndpoint.schema.json\n",
    "name: my-mnist-endpoint\n",
    "auth_mode: key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "{\n",
      "  \"auth_mode\": \"key\",\n",
      "  \"id\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AzureML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/onlineEndpoints/my-mnist-endpoint\",\n",
      "  \"identity\": {\n",
      "    \"principal_id\": \"8936e704-6573-4eb2-8df5-aa5bde220299\",\n",
      "    \"tenant_id\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "    \"type\": \"system_assigned\"\n",
      "  },\n",
      "  \"location\": \"eastus\",\n",
      "  \"name\": \"my-mnist-endpoint\",\n",
      "  \"properties\": {\n",
      "    \"AzureAsyncOperationUri\": \"https://management.azure.com/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oe:dd33cef1-2535-4c5b-947a-0085dbd5db07:f17aaac1-e14f-4ba0-9d29-8ba305d15e9c?api-version=2021-10-01\",\n",
      "    \"azureml.onlineendpointid\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/azureml-rg/providers/microsoft.machinelearningservices/workspaces/ws01/onlineendpoints/my-mnist-endpoint\"\n",
      "  },\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"AzureML-rg\",\n",
      "  \"scoring_uri\": \"https://my-mnist-endpoint.eastus.inference.ml.azure.com/score\",\n",
      "  \"swagger_uri\": \"https://my-mnist-endpoint.eastus.inference.ml.azure.com/swagger.json\",\n",
      "  \"tags\": {},\n",
      "  \"traffic\": {}\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint create --file 08_managed_endpoint.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy as web service\n",
    "\n",
    "Next we deploy the serving code (```score.py```) as a web service in the previous endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deployment, create conda configuration for serving environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 08_conda_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile 08_conda_env.yml\n",
    "name: serving_example\n",
    "dependencies:\n",
    "- python=3.6\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "- tensorflow==1.15\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we deploy a web service with yaml configuration for deployment.\n",
    "\n",
    "When you change the model (or code) in managed endpoint, you can submit multiple deployments and transfer the traffic allocation without causing any disruption.<br>\n",
    "With the following ```--all-traffic``` option, all traffic (100% traffic) will be allocated to this single deployment.\n",
    "\n",
    "In this example, I use the trained model in Exercise04, and **run \"[Exercise04 : Train on Remote GPU Virtual Machine](./exercise04_train_remote.ipynb)\", before running this code.**\n",
    "\n",
    "> Note : You can scale computes by increasing the following ```instance_count```. (You can also define auto-scale settings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 08_managed_deployment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile 08_managed_deployment.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json\n",
    "name: my-mnist-deployment-v1\n",
    "endpoint_name: my-mnist-endpoint\n",
    "model: azureml:mnist_model_test:1\n",
    "code_configuration:\n",
    "  code: \n",
    "    local_path: ./\n",
    "  scoring_script: score.py\n",
    "environment: \n",
    "  conda_file: 08_conda_env.yml\n",
    "  image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\n",
    "instance_type: Standard_DS2_v2\n",
    "instance_count: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-deployment' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "Check: endpoint my-mnist-endpoint exists\n",
      "\u001b[32mUploading cli_yaml (61.18 MBs): 100%|â–ˆ| 61180104/61180104 [00:01<00:00, 50106038\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "The deployment request ws01-my-mnist-endpoint-6872361 was accepted. ARM deployment URI for reference: \n",
      "https://ms.portal.azure.com/#blade/HubsExtension/DeploymentDetailsBlade/overview/id/%2Fsubscriptions%2Fb3ae1c15-4fef-4362-8c3a-5d804cdeb18d%2FresourceGroups%2FAzureML-rg%2Fproviders%2FMicrosoft.Resources%2Fdeployments%2Fws01-my-mnist-endpoint-6872361\n",
      "Registering environment version: (b562c3a6-a6a5-47a7-a5dd-cf96170c281c 1 )  Done (2s)\n",
      "Registering code version: (cd4bb3ef-2e9e-45f6-858a-421eb6b8dcb9 1 )  Done (0s)\n",
      "Creating or updating deployment: my-mnist-deployment-v1   .......................................................................  Done (6m 10s)\n",
      "Total time : 6m 12s\n",
      "{\n",
      "  \"app_insights_enabled\": false,\n",
      "  \"code_configuration\": {\n",
      "    \"code\": {\n",
      "      \"code_uri\": \"https://ws019776884828.blob.core.windows.net/azureml-blobstore-dd33cef1-2535-4c5b-947a-0085dbd5db07/LocalUpload/3baafdabfc3417f110c27e234cb74b30/cli_yaml\",\n",
      "      \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AzureML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/codes/cd4bb3ef-2e9e-45f6-858a-421eb6b8dcb9/versions/1\",\n",
      "      \"local_path\": \"/home/tsmatsuz/cli_yaml\",\n",
      "      \"name\": \"cd4bb3ef-2e9e-45f6-858a-421eb6b8dcb9\",\n",
      "      \"resourceGroup\": \"AzureML-rg\",\n",
      "      \"tags\": {},\n",
      "      \"version\": \"1\"\n",
      "    },\n",
      "    \"scoring_script\": \"score.py\"\n",
      "  },\n",
      "  \"endpoint_name\": \"my-mnist-endpoint\",\n",
      "  \"environment\": {\n",
      "    \"conda_file\": {\n",
      "      \"channels\": [\n",
      "        \"anaconda\",\n",
      "        \"conda-forge\"\n",
      "      ],\n",
      "      \"dependencies\": [\n",
      "        \"python=3.6\",\n",
      "        {\n",
      "          \"pip\": [\n",
      "            \"azureml-defaults\"\n",
      "          ]\n",
      "        },\n",
      "        \"tensorflow==1.15\"\n",
      "      ],\n",
      "      \"name\": \"serving_example\"\n",
      "    },\n",
      "    \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AzureML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/environments/b562c3a6-a6a5-47a7-a5dd-cf96170c281c/versions/1\",\n",
      "    \"image\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
      "    \"name\": \"b562c3a6-a6a5-47a7-a5dd-cf96170c281c\",\n",
      "    \"resourceGroup\": \"AzureML-rg\",\n",
      "    \"tags\": {},\n",
      "    \"version\": \"1\"\n",
      "  },\n",
      "  \"environment_variables\": {},\n",
      "  \"instance_count\": 1,\n",
      "  \"instance_type\": \"Standard_DS2_v2\",\n",
      "  \"model\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AzureML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/models/mnist_model_test/versions/1\",\n",
      "  \"name\": \"my-mnist-deployment-v1\",\n",
      "  \"properties\": {},\n",
      "  \"tags\": {},\n",
      "  \"type\": \"managed\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-deployment create --file 08_managed_deployment.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --all-traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see logs as follows, if error has occured.<br>\n",
    "For instance, the following log output shows Python import error in entry script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-deployment' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "Instance status:\n",
      "SystemSetup: Succeeded\n",
      "UserContainerImagePull: Succeeded\n",
      "ModelDownload: Succeeded\n",
      "UserContainerStart: InProgress\n",
      "\n",
      "Container logs:\n",
      "2022-02-28T07:19:01,824500903+00:00 - rsyslog/run \n",
      "2022-02-28T07:19:01,827055025+00:00 - gunicorn/run \n",
      "Dynamic Python package installation is disabled.\n",
      "Starting HTTP server\n",
      "2022-02-28T07:19:01,844367081+00:00 - nginx/run \n",
      "2022-02-28T07:19:01,856197687+00:00 - iot-server/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2022-02-28T07:19:02,048559714+00:00 - iot-server/finish 1 0\n",
      "2022-02-28T07:19:02,050840535+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 37\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2022-02-28 07:19:05,419 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2022-02-28 07:19:05,419 | root | INFO | Starting up request id generator\n",
      "2022-02-28 07:19:05,419 | root | INFO | Starting up app insight hooks\n",
      "2022-02-28 07:19:05,419 | root | INFO | Invoking user's init function\n",
      "2022-02-28 07:19:05,419 | root | ERROR | User's init function failed\n",
      "2022-02-28 07:19:05,420 | root | ERROR | Encountered Exception Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 191, in register\n",
      "    main.init()\n",
      "  File \"/var/azureml-app/cli_yaml/score.py\", line 8, in init\n",
      "    model_path = os.path.join(\n",
      "NameError: name 'os' is not defined\n",
      "\n",
      "2022-02-28 07:19:05,420 | root | INFO | Waiting for logs to be sent to Application Insights before exit.\n",
      "2022-02-28 07:19:05,420 | root | INFO | Waiting 30 seconds for upload.\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-deployment get-logs --endpoint-name my-mnist-endpoint \\\n",
    "  --name my-mnist-deployment-v1 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : Before submitting a deployment on cloud, you can submit and debug your deployment on local docker runtime. (See [here](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-managed-online-endpoints).)<br>\n",
    "> With Visual Studio Code, you can also attach debugger on local deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your web service\n",
    "\n",
    "Let's invoke your deployed web service and check the returned results in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First see URI (address) for your deployed web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "\"https://my-mnist-endpoint.eastus.inference.ml.azure.com/score\"\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint show --name my-mnist-endpoint \\\n",
    "  --query scoring_uri \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract key credential for this endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "{\n",
      "  \"primaryKey\": \"3cMIeMz6TJQlSqrIVxeZXRFBaGrEFhdq\",\n",
      "  \"secondaryKey\": \"S5NEF60bf6nlqLoPcKnrnBttILZaxSu6\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint get-credentials \\\n",
    "  --name my-mnist-endpoint \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's invoke scoring web service in Python.<br>\n",
    "(**Replace the following ```SERVING_URI``` and ```API_KEY``` with yours**.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted :  [7, 2, 1]\n",
      "Actual    :  [7, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "SERVING_URI = \"https://my-mnist-endpoint.eastus.inference.ml.azure.com/score\"\n",
    "API_KEY = \"3cMIeMz6TJQlSqrIVxeZXRFBaGrEFhdq\"\n",
    "\n",
    "# Read data by tensor\n",
    "tfdata = tf.data.TFRecordDataset('./data/test.tfrecords')\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(tfdata)\n",
    "data_org = iterator.get_next()\n",
    "###\n",
    "data_exam = tf.parse_single_example(\n",
    "    data_org,\n",
    "    features={\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "data_image.set_shape([784])\n",
    "data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "\n",
    "# Run tensor and generate data\n",
    "with tf.Session() as sess:\n",
    "    image_arr = []\n",
    "    label_arr = []\n",
    "    for i in range(3):\n",
    "        image, label = sess.run([data_image, data_label])\n",
    "        image_arr.append(image.tolist())\n",
    "        label_arr.append(label)\n",
    "\n",
    "# Invoke web service !\n",
    "headers = {\n",
    "    'Content-Type':'application/json',\n",
    "    'Authorization':('Bearer '+ API_KEY)\n",
    "} \n",
    "values = json.dumps(image_arr)\n",
    "input_data = \"{\\\"data\\\": \" + values + \"}\"\n",
    "http_res = requests.post(\n",
    "    SERVING_URI,\n",
    "    input_data,\n",
    "    headers = headers)\n",
    "print('Predicted : ', http_res.text)\n",
    "print('Actual    : ', label_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml online-endpoint' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "Deleting endpoint my-mnist-endpoint ........................................................................Done (6m 8s)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint delete --name my-mnist-endpoint \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
