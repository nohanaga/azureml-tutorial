{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise04 : Train on Remote GPU Virtual Machine\n",
    "\n",
    "Now we run our previous sample (see \"[Exercise03 : Just Train in Your Working Machine](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/blob/master/notebooks/exercise03_train_simple.ipynb)\") on remote virtual machine with GPU utilized.    \n",
    "Here we use remote virtual machine and conda virtual environment, but you can also use Batch AI pool sharing in your team, or run on your favorite docker images.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your training script as file (train.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ```scirpt``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please add the following ```%%writefile``` at the beginning of the source code in \"[Exercise03 : Just Train in Your Working Machine](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/blob/master/notebooks/exercise03_train_simple.ipynb)\", and run this cell.    \n",
    "Then this source code is saved as ```./script/train.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None\n",
    "batch_size = 100\n",
    "\n",
    "#\n",
    "# define functions for Estimator\n",
    "#\n",
    "\n",
    "def _my_input_fn(filepath, num_epochs):\n",
    "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
    "    # label - digit (0, 1, ..., 9)\n",
    "    data_queue = tf.train.string_input_producer(\n",
    "        [filepath],\n",
    "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
    "    data_reader = tf.TFRecordReader()\n",
    "    _, serialized_exam = data_reader.read(data_queue)\n",
    "    data_exam = tf.parse_single_example(\n",
    "        serialized_exam,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "    data_image.set_shape([784])\n",
    "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "    data_batch_image, data_batch_label = tf.train.batch(\n",
    "        [data_image, data_label],\n",
    "        batch_size=batch_size)\n",
    "    return {'inputs': data_batch_image}, data_batch_label\n",
    "\n",
    "def _get_input_fn(filepath, num_epochs):\n",
    "    return lambda: _my_input_fn(filepath, num_epochs)\n",
    "\n",
    "def _my_model_fn(features, labels, mode):\n",
    "    # with tf.device(...): # You can set device if using GPUs\n",
    "\n",
    "    # define network and inference\n",
    "    # (simple 2 fully connected hidden layer : 784->128->64->10)\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [784, FLAGS.first_layer],\n",
    "                stddev=1.0 / math.sqrt(float(784))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.first_layer]),\n",
    "            name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(features['inputs'], weights) + biases)\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.first_layer, FLAGS.second_layer],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.first_layer))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.second_layer]),\n",
    "            name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.second_layer, 10],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.second_layer))),\n",
    "        name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([10]),\n",
    "            name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    " \n",
    "    # compute evaluation matrix\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        label_indices = tf.cast(labels, tf.int32)\n",
    "        accuracy = tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "        tf.summary.scalar('accuracy', accuracy[1]) # output to TensorBoard\n",
    " \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels,\n",
    "            logits=logits)\n",
    " \n",
    "    # define operations\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #global_step = tf.train.create_global_step()\n",
    "        #global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        global_step = tf.train.get_or_create_global_step()        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=FLAGS.learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "        predictions = {\n",
    "            'classes': predicted_indices,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            predictions=predictions,\n",
    "            export_outputs=export_outputs)\n",
    "\n",
    "def _my_serving_input_fn():\n",
    "    inputs = {'inputs': tf.placeholder(tf.float32, [None, 784])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "#\n",
    "# Main\n",
    "#\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data_folder',\n",
    "    type=str,\n",
    "    default='./data',\n",
    "    help='Folder path for input data')\n",
    "parser.add_argument(\n",
    "    '--chkpoint_folder',\n",
    "    type=str,\n",
    "    default='./logs',  # AML experiments logs folder\n",
    "    help='Folder path for checkpoint files')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./outputs',  # AML experiments outputs folder\n",
    "    help='Folder path for model output')\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default='0.07',\n",
    "    help='Learning Rate')\n",
    "parser.add_argument(\n",
    "    '--first_layer',\n",
    "    type=int,\n",
    "    default='128',\n",
    "    help='Neuron number for the first hidden layer')\n",
    "parser.add_argument(\n",
    "    '--second_layer',\n",
    "    type=int,\n",
    "    default='64',\n",
    "    help='Neuron number for the second hidden layer')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# clean checkpoint and model folder if exists\n",
    "if os.path.exists(FLAGS.chkpoint_folder) :\n",
    "    for file_name in os.listdir(FLAGS.chkpoint_folder):\n",
    "        file_path = os.path.join(FLAGS.chkpoint_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "if os.path.exists(FLAGS.model_folder) :\n",
    "    for file_name in os.listdir(FLAGS.model_folder):\n",
    "        file_path = os.path.join(FLAGS.model_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "# read TF_CONFIG\n",
    "run_config = tf.estimator.RunConfig()\n",
    "\n",
    "# create Estimator\n",
    "mnist_fullyconnected_classifier = tf.estimator.Estimator(\n",
    "    model_fn=_my_model_fn,\n",
    "    model_dir=FLAGS.chkpoint_folder,\n",
    "    config=run_config)\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'train.tfrecords'), 2),\n",
    "    max_steps=60000 * 2 / batch_size)\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
    "    steps=10000 * 1 / batch_size,\n",
    "    start_delay_secs=0)\n",
    "\n",
    "# run !\n",
    "tf.estimator.train_and_evaluate(\n",
    "    mnist_fullyconnected_classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_dir = mnist_fullyconnected_classifier.export_savedmodel(\n",
    "    export_dir_base = FLAGS.model_folder,\n",
    "    serving_input_receiver_fn = _my_serving_input_fn)\n",
    "print('current working directory is ', os.getcwd())\n",
    "print('model is saved ', model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on remote VM\n",
    "\n",
    "Now let's start to integrate with AML services and run training on remote virtual machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Get workspace setting\n",
    "\n",
    "Before starting, you must read your configuration settings. (See \"[Exercise01 : Prepare Config Settings](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/blob/master/notebooks/exercise01_prepare_config.ipynb)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Create new remote virtual machine\n",
    "\n",
    "Create your new Data Science Virtual Machine (which is pre-configured for data science) with **GPU** (NC6). Before starting, please make sure to use NC6 supported location as workspace location. By enabling auto-scaling (from 0 to 1), you can save money (the node is terminated) if it's inactive.    \n",
    "If already exists, this script will get the existing one.\n",
    "\n",
    "You can also attach an existing virtual machine (bring your own compute resource) as a compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new.\n",
      "InProgress......\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name='mydsvm01')\n",
    "    print('found existing:', compute_target.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='STANDARD_NC6',\n",
    "        min_nodes=0,\n",
    "        max_nodes=1)\n",
    "    compute_target = ComputeTarget.create(ws, 'mydsvm01', compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Get dataset reference for files\n",
    "\n",
    "You can use registered dataset (train.tfrecords, test.tfrecords) to mount in your compute target.    \n",
    "See \"[Exercise02 : Prepare Data](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/blob/master/notebooks/exercise02_prepare_data.ipynb)\" for data preparation.\n",
    "\n",
    "> Note : Dataset registration is not mandatory. (You can mount any data (as dataset) in AML datastore.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, 'mnist_tfrecords_dataset', version='latest')\n",
    "\n",
    "# # For using unregistered data, see below\n",
    "# from azureml.core import Datastore\n",
    "# from azureml.core import Dataset\n",
    "# ds = ws.get_default_datastore()\n",
    "# ds_paths = [(ds, 'tfdata/')]\n",
    "# dataset = Dataset.File.from_files(path = ds_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Create environment\n",
    "\n",
    "Here we set docker environments for running scripts. In the first time, it will generate our own conatiner image as following settings. (It will then take a long time for completing experiment.)\n",
    "However, you can speed up by reusing the generated environment in the next run, once you have registered the generated environment.\n",
    "\n",
    "In this example, we create our own environment manually, but **you can also use existing environments (called, curated environments) for a variety of purposes**. (It also includes an environment for running TensorFlow 1.x.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04:20210714.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"test-remote-gpu-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults~=1.33.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"tensorflow-gpu==1.15\"\n",
       "            ],\n",
       "            \"name\": \"azureml_02cb4dd66a36882cd7876a87ad6f1407\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "# create environment\n",
    "env = Environment('test-remote-gpu-env')\n",
    "env.python.conda_dependencies = CondaDependencies.create(\n",
    "    python_version=\"3.6\",\n",
    "    conda_packages=['tensorflow-gpu==1.15'])\n",
    "env.docker.base_image = DEFAULT_GPU_IMAGE\n",
    "\n",
    "# register environment to re-use later\n",
    "env.register(workspace=ws)\n",
    "## # speed up by using the existing environment\n",
    "## env = Environment.get(ws, name='test-remote-gpu-env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Run script and wait for completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: tf_remote_experiment_1629700356_fa43b5c1\n",
      "Web View: https://ml.azure.com/runs/tf_remote_experiment_1629700356_fa43b5c1?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/TESTML-rg/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2021-08-23T06:33:18Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=305382 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-08-23T06:33:18Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore\n",
      "2021-08-23T06:33:18Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-08-23T06:33:18Z Starting output-watcher...\n",
      "2021-08-23T06:33:19Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-08-23T06:33:19Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-23T06:33:19Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_1e5b59c0734bdc528077f509e1d397fe\n",
      "Digest: sha256:d0c5e40cf440c619e721faa614dc94fe56cb6c41768532d169421cbe2288edc7\n",
      "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_1e5b59c0734bdc528077f509e1d397fe:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_1e5b59c0734bdc528077f509e1d397fe:latest\n",
      "2021-08-23T06:33:19Z Check if container tf_remote_experiment_1629700356_fa43b5c1_DataSidecar already exist exited with 0, \n",
      "\n",
      "930eb41b184303d7f9780d1d4814d5b57bef77b0833ef068a18845d744a66834\n",
      "2021-08-23T06:33:20Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-08-23T06:33:20Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-daf2f07068f5a86bb3479924686c08f2-51cff9c72bcd4c6e-01 -sshRequired=false] \n",
      "2021/08/23 06:33:20 Starting App Insight Logger for task:  containerSetup\n",
      "2021/08/23 06:33:20 Version: 3.0.01685.0003 Branch: 2021-08-13 Commit: c4f2540\n",
      "2021/08/23 06:33:20 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/08/23 06:33:20 Starting infiniband setup\n",
      "2021/08/23 06:33:20 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/23 06:33:20 Returning Python Version as 3.7\n",
      "2021-08-23T06:33:20Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021-08-23T06:33:20Z Not setting up Infiniband in Container\n",
      "2021/08/23 06:33:20 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/23 06:33:20 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/23 06:33:20 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/08/23 06:33:20 Not setting up Infiniband in Container\n",
      "2021/08/23 06:33:20 Not setting up Infiniband in Container\n",
      "2021/08/23 06:33:20 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/23 06:33:20 Returning Python Version as 3.7\n",
      "2021/08/23 06:33:20 sshd inside container not required for job, skipping setup.\n",
      "2021/08/23 06:33:20 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/08/23 06:33:20 App Insight Client has already been closed\n",
      "2021/08/23 06:33:20 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-08-23T06:33:20Z Starting docker container succeeded.\n",
      "2021-08-23T06:33:32Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-23T06:33:32Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_e7bec440fa97f30bf63881052ee5d511\n",
      "Digest: sha256:252c4285298fb4c570d9cb7abde1429d81485ee96b0a9b95dfc7152463a292f7\n",
      "Status: Image is up to date for 295a805f07674e4fa2fec9e7f2fcc812.azurecr.io/azureml/azureml_e7bec440fa97f30bf63881052ee5d511:latest\n",
      "295a805f07674e4fa2fec9e7f2fcc812.azurecr.io/azureml/azureml_e7bec440fa97f30bf63881052ee5d511:latest\n",
      "2021-08-23T06:33:32Z Check if container tf_remote_experiment_1629700356_fa43b5c1 already exist exited with 0, 930eb41b1843\n",
      "\n",
      "\n",
      "2021-08-23T06:33:32Z The container tf_remote_experiment_1629700356_fa43b5c1 already exists, stop and remove it before starting it.\n",
      "2021-08-23T06:33:32Z Stopping container tf_remote_experiment_1629700356_fa43b5c1 exited with 1, Error response from daemon: No such container: tf_remote_experiment_1629700356_fa43b5c1\n",
      "\n",
      "\n",
      "2021-08-23T06:33:32Z Removing container tf_remote_experiment_1629700356_fa43b5c1 exited with 1, Error: No such container: tf_remote_experiment_1629700356_fa43b5c1\n",
      "\n",
      "\n",
      "3da013399f9b96ecc804b29763a81811132987c705755e3398ade56dda1ddb04\n",
      "2021-08-23T06:33:32Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-08-23T06:33:32Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-daf2f07068f5a86bb3479924686c08f2-649c8560904d5123-01 -sshRequired=false] \n",
      "2021/08/23 06:33:32 Starting App Insight Logger for task:  containerSetup\n",
      "2021/08/23 06:33:32 Version: 3.0.01685.0003 Branch: 2021-08-13 Commit: c4f2540\n",
      "2021/08/23 06:33:32 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/08/23 06:33:32 Starting infiniband setup\n",
      "2021/08/23 06:33:32 Python Version found is Python 3.6.12 :: Anaconda, Inc.\n",
      "\n",
      "2021/08/23 06:33:32 Returning Python Version as 3.6\n",
      "2021-08-23T06:33:32Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/23 06:33:32 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/23 06:33:32 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/23 06:33:32 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-08-23T06:33:32Z Not setting up Infiniband in Container\n",
      "2021/08/23 06:33:32 Not setting up Infiniband in Container\n",
      "2021/08/23 06:33:32 Not setting up Infiniband in Container\n",
      "2021/08/23 06:33:32 Python Version found is Python 3.6.12 :: Anaconda, Inc.\n",
      "\n",
      "2021/08/23 06:33:32 Returning Python Version as 3.6\n",
      "2021/08/23 06:33:32 sshd inside container not required for job, skipping setup.\n",
      "2021/08/23 06:33:33 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/08/23 06:33:33 App Insight Client has already been closed\n",
      "2021/08/23 06:33:33 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-08-23T06:33:33Z Starting docker container succeeded.\n",
      "2021-08-23T06:33:34Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/08/23 06:33:18 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/08/23 06:33:18 Version: 3.0.01685.0003 Branch: 2021-08-13 Commit: c4f2540\n",
      ">>>   2021/08/23 06:33:18 runtime.GOOS linux\n",
      ">>>   2021/08/23 06:33:18 Checking if '/tmp' exists\n",
      ">>>   2021/08/23 06:33:18 Reading dyanamic configs\n",
      ">>>   2021/08/23 06:33:18 Container sas url: https://baiscriptseastusprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=gCpFfTbL8hPl%2BzV43hBdfOZC4SuKqZoJraIo10S4%2FYw%3D\n",
      ">>>   2021/08/23 06:33:18 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installer on host: true. Is Azsecpack installation enabled: true,AzSecPack_RoleInstance=\"diagnosticserver-787fbc597c-f528m\"\n",
      ">>>   2021/08/23 06:33:18 Starting Azsecpack installation on machine: dfb91435118246b08946b2cddeb0dedf000000#72f988bf-86f1-41af-91ab-2d7cd011db47#b3ae1c15-4fef-4362-8c3a-5d804cdeb18d#testml-rg#ws01#mydsvm01#tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d\n",
      ">>>   2021/08/23 06:33:18 Is Azsecpack enabled: true, GetDisableVsatlsscan: true\n",
      ">>>   2021/08/23 06:33:18 Start preparing environment for azsecpack installation. MachineName is dfb91435118246b08946b2cddeb0dedf000000 \n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:18 \n",
      ">>>   2021/08/23 06:33:18 \n",
      ">>>   2021/08/23 06:33:18 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2021/08/23 06:33:18 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2021/08/23 06:33:18 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/23 06:33:18 GPU : GPU 0: Tesla K80 (UUID: GPU-c629f41a-29e9-4d41-1fdd-017b9bbc4a0e)\n",
      ">>>   2021/08/23 06:33:18 GPU count found on the node: 1\n",
      ">>>   2021/08/23 06:33:18 Mellanox Inbox drivers found (implying presence of SR-IOV)?: false\n",
      ">>>   2021/08/23 06:33:18 Disabling IB for NCCL.\n",
      ">>>   2021/08/23 06:33:18 AMLComputeXDSEndpoint:  https://eastus-prodk8ds.batchai.core.windows.net\n",
      ">>>   2021/08/23 06:33:18 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/08/23 06:33:18 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config\n",
      ">>>   2021/08/23 06:33:18 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/08/23 06:33:18 Starting identity responder.\n",
      ">>>   2021/08/23 06:33:18 Starting identity responder.\n",
      ">>>   2021/08/23 06:33:18 Logfile used for identity responder: /mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/IdentityResponderLog-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt\n",
      ">>>   2021/08/23 06:33:18 Logfile used for identity responder: /mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/IdentityResponderLog-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt\n",
      ">>>   2021/08/23 06:33:18 Started Identity Responder for job.\n",
      ">>>   2021/08/23 06:33:18 Started Identity Responder for job.\n",
      ">>>   2021/08/23 06:33:18 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd\n",
      ">>>   2021/08/23 06:33:18 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/shared\n",
      ">>>   2021/08/23 06:33:18 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   2021/08/23 06:33:18 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/08/23 06:33:18 Mounting job level file systems\n",
      ">>>   2021/08/23 06:33:18 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts\n",
      ">>>   2021/08/23 06:33:18 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/08/23 06:33:18 Datastore credentials file not found, skipping.\n",
      ">>>   2021/08/23 06:33:18 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.master.runtimesastokens\n",
      ">>>   2021/08/23 06:33:18 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/08/23 06:33:18 NFS mount is not enabled\n",
      ">>>   2021/08/23 06:33:18 No Azure File Shares configured\n",
      ">>>   2021/08/23 06:33:18 Mounting blob file systems\n",
      ">>>   2021/08/23 06:33:18 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/08/23 06:33:18 Mounting azureml-blobstore-295a805f-0767-4e4f-a2fe-c9e7f2fcc812 container from ws016372024076 account at /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore\n",
      ">>>   2021/08/23 06:33:18 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/23 06:33:18 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/23 06:33:18 Blobfuse cache size set to 305382 MB.\n",
      ">>>   2021/08/23 06:33:18 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=305382 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/08/23 06:33:18 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore\n",
      ">>>   2021/08/23 06:33:18 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore\n",
      ">>>   2021/08/23 06:33:18 Successfully mounted azureml-blobstore-295a805f-0767-4e4f-a2fe-c9e7f2fcc812 container from ws016372024076 account at /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore\n",
      ">>>   2021/08/23 06:33:18 Failed to created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore/azureml/tf_remote_experiment_1629700356_fa43b5c1, due to mkdir /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore/azureml/tf_remote_experiment_1629700356_fa43b5c1: read-only file system\n",
      ">>>   2021/08/23 06:33:18 No unmanaged file systems configured\n",
      ">>>   2021/08/23 06:33:18 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/23 06:33:18 GPU : GPU 0: Tesla K80 (UUID: GPU-c629f41a-29e9-4d41-1fdd-017b9bbc4a0e)\n",
      ">>>   2021/08/23 06:33:18 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ">>>   . Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      ">>>   2021/08/23 06:33:18 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ">>>   . Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      ">>>   2021/08/23 06:33:18 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   2021/08/23 06:33:18 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/08/23 06:33:18 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   2021/08/23 06:33:18 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   2021/08/23 06:33:18 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   2021/08/23 06:33:18 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   2021/08/23 06:33:18 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs\n",
      ">>>   2021/08/23 06:33:18 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d\n",
      ">>>   2021/08/23 06:33:18 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d/55_azureml-execution-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt\n",
      ">>>   2021/08/23 06:33:18 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   2021/08/23 06:33:18 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs\n",
      ">>>   2021/08/23 06:33:18 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs\n",
      ">>>   2021/08/23 06:33:18 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs\n",
      ">>>   2021/08/23 06:33:18 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d\n",
      ">>>   2021/08/23 06:33:18 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d/55_azureml-execution-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt\n",
      ">>>   2021/08/23 06:33:18 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs\n",
      ">>>   2021/08/23 06:33:18 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/logs\n",
      ">>>   2021/08/23 06:33:18 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/outputs\n",
      ">>>   2021/08/23 06:33:18 Starting output-watcher...\n",
      ">>>   2021/08/23 06:33:18 Single file input dataset is enabled.\n",
      ">>>   2021/08/23 06:33:18 Begin Sidecar setup\n",
      ">>>   2021/08/23 06:33:18 SingleDataDirectory enabled, Passing to Sidecar.\n",
      ">>>   2021/08/23 06:33:18 Pulling Sidecar docker image: azureml/azureml_1e5b59c0734bdc528077f509e1d397fe\n",
      ">>>   2021/08/23 06:33:18 Start pull docker image: azureml\n",
      ">>>   2021/08/23 06:33:18 Getting credentials for image azureml/azureml_1e5b59c0734bdc528077f509e1d397fe with url \n",
      ">>>   2021/08/23 06:33:18 Container registry is not ACR.\n",
      ">>>   2021/08/23 06:33:18 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/08/23 06:33:18 Getting ACR Credentials from EMS for environment AzureML-Sidecar:22\n",
      ">>>   2021/08/23 06:33:18 Requesting XDS for registry details.\n",
      ">>>   2021/08/23 06:33:18 Attempt 1 of http call to https://eastus-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/testml-rg/workspaces/ws01/clusters/mydsvm01/nodes/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d?api-version=2018-02-01\n",
      ">>>   2021/08/23 06:33:19 Got container registry details from credentials service for registry address: viennaglobal.azurecr.io.\n",
      ">>>   2021/08/23 06:33:19 Writing ACR Details to file...\n",
      ">>>   2021/08/23 06:33:19 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/08/23 06:33:19 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/08/23 06:33:19 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/08/23 06:33:19 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/08/23 06:33:19 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/08/23 06:33:19 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/08/23 06:33:19 EMS returned viennaglobal.azurecr.io for environment AzureML-Sidecar\n",
      ">>>   2021/08/23 06:33:19 Updating image url from blank to viennaglobal.azurecr.io\n",
      ">>>   2021/08/23 06:33:19 Save docker credentials for image viennaglobal.azurecr.io/azureml/azureml_1e5b59c0734bdc528077f509e1d397fe in /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/docker_login_FE1128AEC1DC0CD0\n",
      ">>>   2021/08/23 06:33:19 Start login to the docker registry\n",
      ">>>   2021/08/23 06:33:19 Successfully logged into the docker registry.\n",
      ">>>   2021/08/23 06:33:19 Start run pull docker image command\n",
      ">>>   2021/08/23 06:33:19 Pull docker image succeeded.\n",
      ">>>   2021/08/23 06:33:19 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/docker_login_FE1128AEC1DC0CD0\n",
      ">>>   2021/08/23 06:33:19 Pull docker image time: 665.643837ms\n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:19 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:19 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/23 06:33:19 GPU : GPU 0: Tesla K80 (UUID: GPU-c629f41a-29e9-4d41-1fdd-017b9bbc4a0e)\n",
      ">>>   2021/08/23 06:33:19 Setting the memory limit for docker container to be 55987 MB\n",
      ">>>   2021/08/23 06:33:19 The env variable file size is 40584 bytes\n",
      ">>>   2021/08/23 06:33:19 Creating parent cgroup 'tf_remote_experiment_1629700356_fa43b5c1' for Containers used in Job\n",
      ">>>   2021/08/23 06:33:19 Add parent cgroup 'tf_remote_experiment_1629700356_fa43b5c1' to container 'tf_remote_experiment_1629700356_fa43b5c1_DataSidecar'\n",
      ">>>   2021/08/23 06:33:19 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/08/23 06:33:19 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,tf_remote_experiment_1629700356_fa43b5c1_DataSidecar,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,--gpus,all,-m,55987m,-v,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.batchai.envlist,--cgroup-parent=/tf_remote_experiment_1629700356_fa43b5c1/,--shm-size,2g,-v,/:/mnt/hostfs:rshared,--env,SIDECAR_HOSTFS=/mnt/hostfs,--env,SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1,--env,AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.batchai.envlist,--env,AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true\n",
      ">>>   2021/08/23 06:33:19 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/08/23 06:33:19 the binding /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1 \n",
      ">>>   2021/08/23 06:33:19 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,tf_remote_experiment_1629700356_fa43b5c1_DataSidecar,--gpus,all,-m,55987m,-w,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.batchai.envlist,--cgroup-parent=/tf_remote_experiment_1629700356_fa43b5c1/,--shm-size,2g,--env,SIDECAR_HOSTFS=/mnt/hostfs,--env,SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1,--env,AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.batchai.envlist,--env,AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true,-v,/:/mnt/hostfs:rshared,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1,-v,/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd,-v,/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs\n",
      ">>>   2021/08/23 06:33:19 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name tf_remote_experiment_1629700356_fa43b5c1_DataSidecar --gpus all -m 55987m -w /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.batchai.envlist --cgroup-parent=/tf_remote_experiment_1629700356_fa43b5c1/ --shm-size 2g --env SIDECAR_HOSTFS=/mnt/hostfs --env SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1 --env AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.batchai.envlist --env AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true -v /:/mnt/hostfs:rshared -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1 -v /mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd -v /mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs -d -it --privileged --net=host viennaglobal.azurecr.io/azureml/azureml_1e5b59c0734bdc528077f509e1d397fe\n",
      ">>>   2021/08/23 06:33:19 Check if container tf_remote_experiment_1629700356_fa43b5c1_DataSidecar already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:19 Check if container tf_remote_experiment_1629700356_fa43b5c1_DataSidecar already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:20 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/23 06:33:20 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/23 06:33:20 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-daf2f07068f5a86bb3479924686c08f2-51cff9c72bcd4c6e-01 -sshRequired=false] \n",
      ">>>   2021/08/23 06:33:20 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-daf2f07068f5a86bb3479924686c08f2-51cff9c72bcd4c6e-01 -sshRequired=false] \n",
      ">>>   2021/08/23 06:33:20 Container ssh is not required for job type.\n",
      ">>>   2021/08/23 06:33:20 Starting docker container succeeded.\n",
      ">>>   2021/08/23 06:33:20 Starting docker container succeeded.\n",
      ">>>   2021/08/23 06:33:20 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:20 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/23 06:33:20 GPU : GPU 0: Tesla K80 (UUID: GPU-c629f41a-29e9-4d41-1fdd-017b9bbc4a0e)\n",
      ">>>   2021/08/23 06:33:20 Waiting for sidecar container tf_remote_experiment_1629700356_fa43b5c1_DataSidecar to start running.\n",
      ">>>   2021/08/23 06:33:20 Running command /usr/bin/docker inspect -f {{.State.Running}} tf_remote_experiment_1629700356_fa43b5c1_DataSidecar\n",
      ">>>   2021/08/23 06:33:21 Waiting for sidecar container to be ready.\n",
      ">>>   2021/08/23 06:33:21 Running command /usr/bin/docker exec tf_remote_experiment_1629700356_fa43b5c1_DataSidecar sh -c python -c 'from azureml.sidecar.ipc import IPC_FILE;import os;print(\"IsSidecarReady:{}\".format(os.path.exists(IPC_FILE)))'\n",
      ">>>   2021/08/23 06:33:21 Sidecar container is running and TaskServer is ready.\n",
      ">>>   2021/08/23 06:33:21 Run job preparation command in Sidecar container\n",
      ">>>   2021/08/23 06:33:21 runSpecialJobTask: checking control script content under dir: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore/azureml/tf_remote_experiment_1629700356_fa43b5c1-setup\n",
      ">>>   2021/08/23 06:33:22 runSpecialJobTask: control script dir content: [_tracer.py: size=2022 md5=4c1dd974ef27d1cbec1434a93802ac73; _tracing.py: size=26407 md5=64b473943a5d2905628a9b2097f18081; _vendor_jwt_decode.py: size=2277 md5=d4b49e48ed904f03a4d6ad2f64f17368; azureml_globals.py: size=12242 md5=3700b728b132e633c956f368d13818e4; context_managers.py: size=48073 md5=1d499aa329dc1debda235d60098e98dd; job_prep.py: size=11214 md5=13bb64f32d440c1fbaff3644045668fc; log_history_status.py: size=4428 md5=778bbe2bb6cb72340d4344366f752a63; request_utilities.py: size=1185 md5=e053daf561ffebe1c54811d9dc11beaa; run_token_provider.py: size=4228 md5=b167c8697df9c999e3676723caa93cb3; utility_context_managers.py: size=5015 md5=824d969dee21cf92733986c744d17142]\n",
      ">>>   2021/08/23 06:33:22 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs\n",
      ">>>   2021/08/23 06:33:22 runSpecialJobTask: Raw cmd for preparation is passed is: python /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore/azureml/tf_remote_experiment_1629700356_fa43b5c1-setup/job_prep.py --snapshots '[{\"Id\":\"d884c7ef-54ae-4b5a-b3ec-eec1a5fc58f9\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/23 06:33:22 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs/65_job_prep-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt\n",
      ">>>   2021/08/23 06:33:22 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs/65_job_prep-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt\n",
      ">>>   2021/08/23 06:33:22 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1;python /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore/azureml/tf_remote_experiment_1629700356_fa43b5c1-setup/job_prep.py --snapshots '[{\"Id\":\"d884c7ef-54ae-4b5a-b3ec-eec1a5fc58f9\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/23 06:33:22 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/08/23 06:33:22 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-daf2f07068f5a86bb3479924686c08f2-7971655eacece0c9-01 -t tf_remote_experiment_1629700356_fa43b5c1_DataSidecar bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1;python /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/mounts/workspaceblobstore/azureml/tf_remote_experiment_1629700356_fa43b5c1-setup/job_prep.py --snapshots '[{\"Id\":\"d884c7ef-54ae-4b5a-b3ec-eec1a5fc58f9\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/23 06:33:23 Attempt 1 of http call to https://eastus.api.azureml.ms/history/v1.0/private/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/TESTML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/runs/tf_remote_experiment_1629700356_fa43b5c1/spans\n",
      ">>>   2021/08/23 06:33:31 containerName:tf_remote_experiment_1629700356_fa43b5c1_DataSidecar\n",
      ">>>   2021/08/23 06:33:31 sidecar containerName:tf_remote_experiment_1629700356_fa43b5c1_DataSidecar\n",
      ">>>   2021/08/23 06:33:31 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:31 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/23 06:33:31 GPU : GPU 0: Tesla K80 (UUID: GPU-c629f41a-29e9-4d41-1fdd-017b9bbc4a0e)\n",
      ">>>   2021/08/23 06:33:31 sidecar dockerLauncher:docker\n",
      ">>>   2021/08/23 06:33:31 sidecarContainerId:930eb41b184303d7f9780d1d4814d5b57bef77b0833ef068a18845d744a66834\n",
      ">>>   2021/08/23 06:33:31 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:31 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/23 06:33:31 GPU : GPU 0: Tesla K80 (UUID: GPU-c629f41a-29e9-4d41-1fdd-017b9bbc4a0e)\n",
      ">>>   2021/08/23 06:33:31 Docker logs for tf_remote_experiment_1629700356_fa43b5c1_DataSidecar\n",
      ">>>   [2021-08-23T06:33:21.120459] INFO azureml.sidecar.sidecar: Received task: start. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   [2021-08-23T06:33:21.123602] INFO azureml.sidecar.sidecar: Started TaskServer. Address: 127.0.0.1, Port: 59661\n",
      ">>>   [2021-08-23T06:33:24.368511] INFO azureml.sidecar.task.enter_contexts: Constructing Context Managers\n",
      ">>>   Initialize DatasetContextManager.\n",
      ">>>   [2021-08-23T06:33:24.518712] INFO azureml.sidecar.task.enter_contexts: Entering Context Managers\n",
      ">>>   [2021-08-23T06:33:24.522601] INFO azureml.sidecar.context_manager_wrapper: Entering context: Dataset\n",
      ">>>   [2021-08-23T06:33:30.926308] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:22.976239] Entering job preparation.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.704074] Starting job preparation.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.704113] Extracting the control code.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.704416] Starting extract_project.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.704465] Starting to extract zip file.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.720903] Finished extracting zip file.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.723984] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.724031] Start fetching snapshots.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.724064] Start fetching snapshot.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.724087] Retrieving project from snapshot: d884c7ef-54ae-4b5a-b3ec-eec1a5fc58f9\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: Starting the daemon thread to refresh tokens in background for process with pid = 56\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.954766] Finished fetching snapshot.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.954793] Finished fetching snapshots.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.954829] Finished extract_project.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.954889] Finished fetching and extracting the control code.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.960707] Start run_history_prep.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.966692] Job preparation is complete.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.966819] Entering Data Context Managers in Sidecar\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:23.967421] Running Sidecar prep cmd...\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:24.358855] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:24.359503] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: Enter __enter__ of DatasetContextManager\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: SDK version: azureml-core==1.32.0 azureml-dataprep==2.20.1. Session id: 9500bdd4-8e7d-49fd-b18d-29a89e479c66. Run id: tf_remote_experiment_1629700356_fa43b5c1.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [[[Context Manager output has been redacted.]]]\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:31.397349] Ran Sidecar prep cmd.\n",
      ">>>   2021/08/23 06:33:31 runSpecialJobTask->SideCar + : preparation: [2021-08-23T06:33:31.397444] Running Context Managers in Sidecar complete.\n",
      ">>>   2021/08/23 06:33:31 DockerSideCarContainerLogs:\n",
      ">>>   [2021-08-23T06:33:21.120459] INFO azureml.sidecar.sidecar: Received task: start. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   [2021-08-23T06:33:21.123602] INFO azureml.sidecar.sidecar: Started TaskServer. Address: 127.0.0.1, Port: 59661\n",
      ">>>   [2021-08-23T06:33:24.368511] INFO azureml.sidecar.task.enter_contexts: Constructing Context Managers\n",
      ">>>   Initialize DatasetContextManager.\n",
      ">>>   [2021-08-23T06:33:24.518712] INFO azureml.sidecar.task.enter_contexts: Entering Context Managers\n",
      ">>>   [2021-08-23T06:33:24.522601] INFO azureml.sidecar.context_manager_wrapper: Entering context: Dataset\n",
      ">>>   [2021-08-23T06:33:30.926308] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:31 DockerSideCarContainerLogs End\n",
      ">>>   2021/08/23 06:33:31 Job preparation command in Sidecar container completed\n",
      ">>>   2021/08/23 06:33:31 Sidecar setup completed\n",
      ">>>   2021/08/23 06:33:31 Start to pulling docker image: 295a805f07674e4fa2fec9e7f2fcc812.azurecr.io/azureml/azureml_e7bec440fa97f30bf63881052ee5d511\n",
      ">>>   2021/08/23 06:33:31 Start pull docker image: 295a805f07674e4fa2fec9e7f2fcc812.azurecr.io\n",
      ">>>   2021/08/23 06:33:31 Getting credentials for image 295a805f07674e4fa2fec9e7f2fcc812.azurecr.io/azureml/azureml_e7bec440fa97f30bf63881052ee5d511 with url 295a805f07674e4fa2fec9e7f2fcc812.azurecr.io\n",
      ">>>   2021/08/23 06:33:31 Container registry is ACR.\n",
      ">>>   2021/08/23 06:33:31 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/08/23 06:33:31 Getting ACR Credentials from EMS for environment test-remote-gpu-env:1\n",
      ">>>   2021/08/23 06:33:31 Requesting XDS for registry details.\n",
      ">>>   2021/08/23 06:33:31 Attempt 1 of http call to https://eastus-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/testml-rg/workspaces/ws01/clusters/mydsvm01/nodes/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d?api-version=2018-02-01\n",
      ">>>   2021/08/23 06:33:32 Got container registry details from credentials service for registry address: 295a805f07674e4fa2fec9e7f2fcc812.azurecr.io.\n",
      ">>>   2021/08/23 06:33:32 Writing ACR Details to file...\n",
      ">>>   2021/08/23 06:33:32 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/08/23 06:33:32 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/08/23 06:33:32 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/08/23 06:33:32 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/08/23 06:33:32 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/08/23 06:33:32 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/08/23 06:33:32 EMS returned 295a805f07674e4fa2fec9e7f2fcc812.azurecr.io for environment test-remote-gpu-env\n",
      ">>>   2021/08/23 06:33:32 Save docker credentials for image 295a805f07674e4fa2fec9e7f2fcc812.azurecr.io/azureml/azureml_e7bec440fa97f30bf63881052ee5d511 in /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/docker_login_FB03A98123B85454\n",
      ">>>   2021/08/23 06:33:32 Start login to the docker registry\n",
      ">>>   2021/08/23 06:33:32 Successfully logged into the docker registry.\n",
      ">>>   2021/08/23 06:33:32 Start run pull docker image command\n",
      ">>>   2021/08/23 06:33:32 Pull docker image succeeded.\n",
      ">>>   2021/08/23 06:33:32 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/docker_login_FB03A98123B85454\n",
      ">>>   2021/08/23 06:33:32 Pull docker image time: 433.973021ms\n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:32 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:32 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/23 06:33:32 GPU : GPU 0: Tesla K80 (UUID: GPU-c629f41a-29e9-4d41-1fdd-017b9bbc4a0e)\n",
      ">>>   2021/08/23 06:33:32 Setting the memory limit for docker container to be 55987 MB\n",
      ">>>   2021/08/23 06:33:32 The env variable file size is 41248 bytes\n",
      ">>>   2021/08/23 06:33:32 Add parent cgroup 'tf_remote_experiment_1629700356_fa43b5c1' to container 'tf_remote_experiment_1629700356_fa43b5c1'\n",
      ">>>   2021/08/23 06:33:32 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/08/23 06:33:32 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,tf_remote_experiment_1629700356_fa43b5c1,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,--gpus,all,-m,55987m,-v,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.batchai.envlist,--cgroup-parent=/tf_remote_experiment_1629700356_fa43b5c1/,--shm-size,2g,-v,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/input__f322f95f_f322f95f-e57f-4a1a-ab88-0a3aff21e21a:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/input__f322f95f_f322f95f-e57f-4a1a-ab88-0a3aff21e21a:rslave\n",
      ">>>   2021/08/23 06:33:32 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/08/23 06:33:32 the binding /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1 \n",
      ">>>   2021/08/23 06:33:32 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,tf_remote_experiment_1629700356_fa43b5c1,--gpus,all,-m,55987m,-w,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.batchai.envlist,--cgroup-parent=/tf_remote_experiment_1629700356_fa43b5c1/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1,-v,/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd,-v,/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs,-v,/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/input__f322f95f_f322f95f-e57f-4a1a-ab88-0a3aff21e21a:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/input__f322f95f_f322f95f-e57f-4a1a-ab88-0a3aff21e21a:rslave\n",
      ">>>   2021/08/23 06:33:32 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name tf_remote_experiment_1629700356_fa43b5c1 --gpus all -m 55987m -w /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/config/.batchai.envlist --cgroup-parent=/tf_remote_experiment_1629700356_fa43b5c1/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1 -v /mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/wd -v /mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs:/mnt/batch/tasks/workitems/6e46227e-980b-4376-9c82-3bf8a75247b7/job-1/tf_remote_experiment_ef4cc4b2-ba98-4827-b8a4-d67bd9b79be9/certs -v /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/input__f322f95f_f322f95f-e57f-4a1a-ab88-0a3aff21e21a:/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/input__f322f95f_f322f95f-e57f-4a1a-ab88-0a3aff21e21a:rslave -d -it --privileged --net=host 295a805f07674e4fa2fec9e7f2fcc812.azurecr.io/azureml/azureml_e7bec440fa97f30bf63881052ee5d511\n",
      ">>>   2021/08/23 06:33:32 Check if container tf_remote_experiment_1629700356_fa43b5c1 already exist exited with 0, 930eb41b1843\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:32 Check if container tf_remote_experiment_1629700356_fa43b5c1 already exist exited with 0, 930eb41b1843\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:32 The container tf_remote_experiment_1629700356_fa43b5c1 already exists, stop and remove it before starting it.\n",
      ">>>   2021/08/23 06:33:32 The container tf_remote_experiment_1629700356_fa43b5c1 already exists, stop and remove it before starting it.\n",
      ">>>   2021/08/23 06:33:32 Stopping container tf_remote_experiment_1629700356_fa43b5c1 exited with 1, Error response from daemon: No such container: tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:32 Stopping container tf_remote_experiment_1629700356_fa43b5c1 exited with 1, Error response from daemon: No such container: tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:32 Removing container tf_remote_experiment_1629700356_fa43b5c1 exited with 1, Error: No such container: tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:32 Removing container tf_remote_experiment_1629700356_fa43b5c1 exited with 1, Error: No such container: tf_remote_experiment_1629700356_fa43b5c1\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/23 06:33:32 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/23 06:33:32 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/23 06:33:32 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-daf2f07068f5a86bb3479924686c08f2-649c8560904d5123-01 -sshRequired=false] \n",
      ">>>   2021/08/23 06:33:32 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-daf2f07068f5a86bb3479924686c08f2-649c8560904d5123-01 -sshRequired=false] \n",
      ">>>   2021/08/23 06:33:33 Container ssh is not required for job type.\n",
      ">>>   2021/08/23 06:33:33 Starting docker container succeeded.\n",
      ">>>   2021/08/23 06:33:33 Starting docker container succeeded.\n",
      ">>>   2021/08/23 06:33:33 Disk space after starting docker container: 312713MB\n",
      ">>>   2021/08/23 06:33:33 Attempt 1 of http call to https://eastus.api.azureml.ms/history/v1.0/private/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/TESTML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/runs/tf_remote_experiment_1629700356_fa43b5c1/spans\n",
      ">>>   2021/08/23 06:33:33 Process Exiting with Code:  0\n",
      ">>>   2021/08/23 06:33:34 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      ">>>   \n",
      "2021-08-23T06:33:34Z 127.0.0.1 slots=1 max-slots=1\n",
      "2021-08-23T06:33:34Z launching Custom job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "2021/08/23 06:33:34 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/08/23 06:33:34 Version: 3.0.01685.0003 Branch: 2021-08-13 Commit: c4f2540\n",
      "2021/08/23 06:33:34 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/08/23 06:33:34 Send process info logs to master server succeeded\n",
      "2021/08/23 06:33:34 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/23 06:33:34 Send process info logs to master server succeeded\n",
      "[2021-08-23T06:33:34.342731] Entering context manager injector.\n",
      "[2021-08-23T06:33:34.859103] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['train.py', '--data_folder', 'DatasetConsumptionConfig:input__f322f95f'])\n",
      "Script type = None\n",
      "[2021-08-23T06:33:34.863132] Entering Run History Context Manager.\n",
      "[2021-08-23T06:33:35.501852] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      "[2021-08-23T06:33:35.502089] Preparing to call script [train.py] with arguments:['--data_folder', '$input__f322f95f']\n",
      "[2021-08-23T06:33:35.502180] After variable expansion, calling script [train.py] with arguments:['--data_folder', '/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/input__f322f95f_f322f95f-e57f-4a1a-ab88-0a3aff21e21a']\n",
      "\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_02cb4dd66a36882cd7876a87ad6f1407/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From train.py:25: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_02cb4dd66a36882cd7876a87ad6f1407/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_02cb4dd66a36882cd7876a87ad6f1407/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_02cb4dd66a36882cd7876a87ad6f1407/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_02cb4dd66a36882cd7876a87ad6f1407/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_02cb4dd66a36882cd7876a87ad6f1407/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_02cb4dd66a36882cd7876a87ad6f1407/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From train.py:26: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From train.py:28: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:31: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:40: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From train.py:53: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:86: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:87: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:89: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_02cb4dd66a36882cd7876a87ad6f1407/lib/python3.6/site-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From train.py:97: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:98: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "2021-08-23 06:33:37.087500: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-08-23 06:33:37.094076: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2596985000 Hz\n",
      "2021-08-23 06:33:37.094574: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a458b6f990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-23 06:33:37.094597: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-08-23 06:33:37.096035: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-23 06:33:37.137136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0726:00:00.0\n",
      "2021-08-23 06:33:37.137391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-23 06:33:37.138768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-23 06:33:37.139989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-23 06:33:37.140324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-23 06:33:37.141912: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-23 06:33:37.144809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-23 06:33:37.148901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-23 06:33:37.150402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-08-23 06:33:37.150456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-23 06:33:37.306810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-23 06:33:37.306846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-08-23 06:33:37.306856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-08-23 06:33:37.309106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10812 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0726:00:00.0, compute capability: 3.7)\n",
      "2021-08-23 06:33:37.311558: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a459a13fd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-23 06:33:37.311581: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_02cb4dd66a36882cd7876a87ad6f1407/lib/python3.6/site-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "2021-08-23 06:33:38.077993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021/08/23 06:33:39 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-08-23T06:33:53.939000] Entering job release\n",
      "[2021-08-23T06:33:54.755197] Starting job release\n",
      "[2021-08-23T06:33:54.755622] Logging experiment finalizing status in history service.\n",
      "[2021-08-23T06:33:54.755868] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 289[2021-08-23T06:33:54.756123] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "\n",
      "[2021-08-23T06:33:54.756371] job release stage : execute_job_release starting...[2021-08-23T06:33:54.756547] job release stage : copy_batchai_cached_logs starting...\n",
      "\n",
      "\n",
      "[2021-08-23T06:33:54.758765] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-08-23T06:33:54.769772] Entering context manager injector.\n",
      "[2021-08-23T06:33:54.774047] job release stage : upload_datastore completed...\n",
      "[2021-08-23T06:33:54.852122] job release stage : send_run_telemetry starting...\n",
      "[2021-08-23T06:33:54.864132] get vm size and vm region successfully.\n",
      "[2021-08-23T06:33:54.874365] get compute meta data successfully.\n",
      "[2021-08-23T06:33:55.013569] job release stage : execute_job_release completed...\n",
      "[2021-08-23T06:33:55.078462] post artifact meta request successfully.\n",
      "[2021-08-23T06:33:55.103200] upload compute record artifact successfully.\n",
      "[2021-08-23T06:33:55.103251] job release stage : send_run_telemetry completed...\n",
      "[2021-08-23T06:33:55.103537] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-08-23T06:33:55.103622] Running Sidecar release cmd...\n",
      "[2021-08-23T06:33:55.114055] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/azureml/tf_remote_experiment_1629700356_fa43b5c1\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/input__f322f95f_f322f95f-e57f-4a1a-ab88-0a3aff21e21a.\n",
      "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/input__f322f95f_f322f95f-e57f-4a1a-ab88-0a3aff21e21a: Invalid argument\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_remote_experiment_1629700356_fa43b5c1/wd/input__f322f95f_f322f95f-e57f-4a1a-ab88-0a3aff21e21a.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-08-23T06:33:55.154954] Removing absolute paths from host...\n",
      "[2021-08-23T06:33:55.155166] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-08-23T06:33:55.809268] Ran Sidecar release cmd.\n",
      "[2021-08-23T06:33:55.809360] Job release is complete\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: tf_remote_experiment_1629700356_fa43b5c1\n",
      "Web View: https://ml.azure.com/runs/tf_remote_experiment_1629700356_fa43b5c1?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/TESTML-rg/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'tf_remote_experiment_1629700356_fa43b5c1',\n",
       " 'target': 'mydsvm01',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-08-23T06:33:17.227186Z',\n",
       " 'endTimeUtc': '2021-08-23T06:34:03.49605Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'd884c7ef-54ae-4b5a-b3ec-eec1a5fc58f9',\n",
       "  'azureml.git.repository_uri': 'https://github.com/tsmatz/azureml-tutorial-tensorflow-v1.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/tsmatz/azureml-tutorial-tensorflow-v1.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '31b764a4f6cc965ed3fe81e5d3fddf20eb29d690',\n",
       "  'mlflow.source.git.commit': '31b764a4f6cc965ed3fe81e5d3fddf20eb29d690',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'f322f95f-e57f-4a1a-ab88-0a3aff21e21a'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__f322f95f', 'mechanism': 'Mount'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--data_folder', 'DatasetConsumptionConfig:input__f322f95f'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'mydsvm01',\n",
       "  'dataReferences': {},\n",
       "  'data': {'input__f322f95f': {'dataLocation': {'dataset': {'id': 'f322f95f-e57f-4a1a-ab88-0a3aff21e21a',\n",
       "      'name': 'mnist_tfrecords_dataset',\n",
       "      'version': '1'},\n",
       "     'dataPath': None,\n",
       "     'uri': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'input__f322f95f',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'test-remote-gpu-env',\n",
       "   'version': '1',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6',\n",
       "      {'pip': ['azureml-defaults~=1.33.0']},\n",
       "      'tensorflow-gpu==1.15'],\n",
       "     'name': 'azureml_02cb4dd66a36882cd7876a87ad6f1407'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04:20210714.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'AISupercomputer.D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': [],\n",
       "  'dataBricks': {'workers': 0,\n",
       "   'minimumWorkerCount': 0,\n",
       "   'maxMumWorkerCount': 0,\n",
       "   'sparkVersion': '4.0.x-scala2.11',\n",
       "   'nodeTypeId': 'Standard_D3_v2',\n",
       "   'sparkConf': {},\n",
       "   'sparkEnvVars': {},\n",
       "   'instancePoolId': None,\n",
       "   'timeoutSeconds': 0,\n",
       "   'jarLibraries': [],\n",
       "   'eggLibraries': [],\n",
       "   'whlLibraries': [],\n",
       "   'pypiLibraries': [],\n",
       "   'rCranLibraries': [],\n",
       "   'mavenLibraries': []}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/azureml-logs/55_azureml-execution-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt?sv=2019-07-07&sr=b&sig=icM9NXe%2FRqwcze00LHFcv0he9h2J2mY8CuIdXBF1gfM%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/azureml-logs/65_job_prep-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt?sv=2019-07-07&sr=b&sig=FVWMw9LQ1Hmik%2Bep8jdGMyeaO5Y9aSdZn6mUQ2kmBRM%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=32pPuMrIjL2lFJrgRHwkgjHHCd3yDi1x3m0lTBTRLGY%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/azureml-logs/75_job_post-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt?sv=2019-07-07&sr=b&sig=0FSooLqj98NzWSshxI2SHsFnQ%2B4nG9kjbQgyYpB3bos%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=iZwuSsR%2BgCQuLlRlJ1k%2Bs%2FL6BkVOs24J5Cv648bVBBk%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=9lSKAAUv7KjXGfWiZnznoBqLp0eISsS2YGKYGoHlejE%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=xs4TU1C1Z%2Bq0jTCODdt8AINMs0ZrWBbDWg0MK%2FQPI1g%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=FeKsOfcBmEiDJGELcnMGIR%2F9AttRfu2Jwz1mAgbvdHE%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=MRVfG47zEnr6dMRl6rE15DYNQNwI8S7DfV9t2i1RUqM%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d/all.log': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/sidecar/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d/all.log?sv=2019-07-07&sr=b&sig=98Cxw3ppiHgrzdAev%2BdI%2B45PxKbSazcaBNS2ck3pXVg%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d/task.exit_contexts.log': 'https://ws016372024076.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1629700356_fa43b5c1/logs/azureml/sidecar/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=cEFvkFlWH1vRtghiussrkP3MZl0M3e3g98P7cZDSD2c%3D&st=2021-08-23T06%3A24%3A11Z&se=2021-08-23T14%3A34%3A11Z&sp=r'},\n",
       " 'submittedBy': 'Tsuyoshi Matsuzaki'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Run\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "# create script run config\n",
    "src = ScriptRunConfig(\n",
    "    source_directory='./script',\n",
    "    script='train.py',\n",
    "    arguments=['--data_folder', dataset.as_mount()],\n",
    "    compute_target=compute_target,\n",
    "    environment=env,\n",
    "    docker_runtime_config=DockerConfiguration(use_docker=True))\n",
    "\n",
    "# submit and run !\n",
    "exp = Experiment(workspace=ws, name='tf_remote_experiment')\n",
    "run = exp.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Download results and check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check generated files and logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/55_azureml-execution-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt',\n",
       " 'azureml-logs/70_driver_log.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d.txt',\n",
       " 'azureml-logs/process_info.json',\n",
       " 'azureml-logs/process_status.json',\n",
       " 'logs/azureml/dataprep/backgroundProcess.log',\n",
       " 'logs/azureml/dataprep/backgroundProcess_Telemetry.log',\n",
       " 'logs/azureml/job_release_azureml.log',\n",
       " 'logs/azureml/sidecar/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d/all.log',\n",
       " 'logs/azureml/sidecar/tvmps_27f5185a3d5bae9027315a351103ea83c1a6a51c2e9cc3ace3bd723df7a5c7a0_d/task.exit_contexts.log',\n",
       " 'logs/checkpoint',\n",
       " 'logs/eval/events.out.tfevents.1629700431.dfb91435118246b08946b2cddeb0dedf000000',\n",
       " 'logs/events.out.tfevents.1629700417.dfb91435118246b08946b2cddeb0dedf000000',\n",
       " 'logs/graph.pbtxt',\n",
       " 'logs/model.ckpt-0.data-00000-of-00001',\n",
       " 'logs/model.ckpt-0.index',\n",
       " 'logs/model.ckpt-0.meta',\n",
       " 'logs/model.ckpt-1100.data-00000-of-00001',\n",
       " 'logs/model.ckpt-1100.index',\n",
       " 'logs/model.ckpt-1100.meta',\n",
       " 'outputs/1629700431/saved_model.pb',\n",
       " 'outputs/1629700431/variables/variables.data-00000-of-00001',\n",
       " 'outputs/1629700431/variables/variables.index']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download model into your local machine.    \n",
    "**Please change ```1629700431``` to meet previous results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.download_file(\n",
    "    name='outputs/1629700431/saved_model.pb',\n",
    "    output_file_path='remote_model/saved_model.pb')\n",
    "run.download_file(\n",
    "    name='outputs/1629700431/variables/variables.data-00000-of-00001',\n",
    "    output_file_path='remote_model/variables/variables.data-00000-of-00001')\n",
    "run.download_file(\n",
    "    name='outputs/1629700431/variables/variables.index',\n",
    "    output_file_path='remote_model/variables/variables.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict your test data using downloaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from ./remote_model/variables/variables\n",
      "Predicted:  [7, 2, 1]\n",
      "Actual   :  [7, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Read data by tensor\n",
    "tfdata = tf.data.TFRecordDataset('./data/test.tfrecords')\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(tfdata)\n",
    "data_org = iterator.get_next()\n",
    "data_exam = tf.parse_single_example(\n",
    "    data_org,\n",
    "    features={\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "data_image.set_shape([784])\n",
    "data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "\n",
    "# Run tensor and generate data\n",
    "with tf.Session() as sess:\n",
    "    image_arr = []\n",
    "    label_arr = []\n",
    "    for i in range(3):\n",
    "        image, label = sess.run([data_image, data_label])\n",
    "        image_arr.append(image)\n",
    "        label_arr.append(label)\n",
    "\n",
    "# Predict\n",
    "pred_fn = tf.contrib.predictor.from_saved_model('./remote_model')\n",
    "pred = pred_fn({'inputs': image_arr})\n",
    "\n",
    "print('Predicted: ', pred['classes'].tolist())\n",
    "print('Actual   : ', label_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 : Register Model with Dataset reference\n",
    "\n",
    "By registering model with dataset reference, you can trace the model with the corresponding dataset version.<br>\n",
    "(**Please change ```1629700431``` to meet previous results.**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(\n",
    "    model_name='mnist_model_test',\n",
    "    model_path='outputs/1629700431',\n",
    "    datasets =[('training data',dataset)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to track data used in this model, see this model in [Azure Machine Learning Studio](https://ml.azure.com/) and select \"Datasets\" tab. (See the following screenshot.)\n",
    "\n",
    "![data tracking](https://tsmatz.files.wordpress.com/2021/08/20210823_track_data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 : Remove AML compute\n",
    "\n",
    "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.    \n",
    "But if you want to clean up, please run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cluster (nbodes) and remove from AML workspace\n",
    "mycompute = AmlCompute(workspace=ws, name='mydsvm01')\n",
    "mycompute.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 1, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-07-12T01:50:09.333000+00:00', 'errors': None, 'creationTime': '2021-07-12T00:41:40.142824+00:00', 'modifiedTime': '2021-07-12T00:42:05.880362+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 1, 'nodeIdleTimeBeforeScaleDown': 'PT1800S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "# get a status for the current cluster.\n",
    "print(mycompute.status.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
