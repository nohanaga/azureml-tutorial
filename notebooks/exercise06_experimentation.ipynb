{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise06 : Experimentation Logs and Outputs\n",
    "\n",
    "Here we add logging capabilities in our source code, and run / check.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get workspace setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/tsmatsuz/azureml-tutorial-tensorflow-v1/notebooks/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(workspace=ws, name='test_experiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change your source code and Train\n",
    "\n",
    "Change your source code in \"[Exercise03 : Just Train in Your Working Machine](./exercise03_train_simple.ipynb)\" for logging in AML as follows. (The lines commented \"##### Modified\" are modified lines.)<br>\n",
    "After running, let's go to [Azure Portal](https://portal.azure.com/) and see how logs look like in AML experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9c8f80ee48>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './logs'}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.293002, step = 1\n",
      "INFO:tensorflow:global_step/sec: 48.2198\n",
      "INFO:tensorflow:loss = 0.54527694, step = 101 (2.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.0178\n",
      "INFO:tensorflow:loss = 0.36972466, step = 201 (2.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.2888\n",
      "INFO:tensorflow:loss = 0.27491865, step = 301 (1.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.6465\n",
      "INFO:tensorflow:loss = 0.51066476, step = 401 (1.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.599\n",
      "INFO:tensorflow:loss = 0.2561956, step = 501 (1.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.1045\n",
      "INFO:tensorflow:loss = 0.32221594, step = 601 (1.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0072\n",
      "INFO:tensorflow:loss = 0.4037928, step = 701 (2.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.5249\n",
      "INFO:tensorflow:loss = 0.2583614, step = 801 (1.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.806\n",
      "INFO:tensorflow:loss = 0.22347087, step = 901 (1.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.9485\n",
      "INFO:tensorflow:loss = 0.26247874, step = 1001 (1.428 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into ./logs/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-11-00:57:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./logs/model.ckpt-1100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-11-00:57:10\n",
      "INFO:tensorflow:Saving dict for global step 1100: accuracy = 0.9328, global_step = 1100, loss = 0.22579904\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1100: ./logs/model.ckpt-1100\n",
      "INFO:tensorflow:Loss for final step: 0.3059145.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from ./logs/model.ckpt-1100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./outputs/temp-b'1544489830'/saved_model.pb\n",
      "current working directory is  /data/home/tsmatsuz/azureml-tutorial-tensorflow-v1/notebooks\n",
      "model is saved  b'./outputs/1544489830'\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from azureml.core.run import Run ##### Modified\n",
    "\n",
    "# Get run when running in remote ##### Modified\n",
    "if 'run' not in locals(): ##### Modified\n",
    "    run = Run.get_context() ##### Modified\n",
    "\n",
    "FLAGS = None\n",
    "batch_size = 100\n",
    "\n",
    "#\n",
    "# define functions for Estimator\n",
    "#\n",
    "\n",
    "def _my_input_fn(filepath, num_epochs):\n",
    "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
    "    # label - digit (0, 1, ..., 9)\n",
    "    data_queue = tf.train.string_input_producer(\n",
    "        [filepath],\n",
    "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
    "    data_reader = tf.TFRecordReader()\n",
    "    _, serialized_exam = data_reader.read(data_queue)\n",
    "    data_exam = tf.parse_single_example(\n",
    "        serialized_exam,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "    data_image.set_shape([784])\n",
    "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "    data_batch_image, data_batch_label = tf.train.batch(\n",
    "        [data_image, data_label],\n",
    "        batch_size=batch_size)\n",
    "    return {'inputs': data_batch_image}, data_batch_label\n",
    "\n",
    "def _get_input_fn(filepath, num_epochs):\n",
    "    return lambda: _my_input_fn(filepath, num_epochs)\n",
    "\n",
    "def _my_model_fn(features, labels, mode):\n",
    "    # with tf.device(...): # You can set device if using GPUs\n",
    "\n",
    "    # define network and inference\n",
    "    # (simple 2 fully connected hidden layer : 784->128->64->10)\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [784, FLAGS.first_layer],\n",
    "                stddev=1.0 / math.sqrt(float(784))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.first_layer]),\n",
    "            name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(features['inputs'], weights) + biases)\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.first_layer, FLAGS.second_layer],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.first_layer))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.second_layer]),\n",
    "            name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.second_layer, 10],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.second_layer))),\n",
    "        name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([10]),\n",
    "            name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    " \n",
    "    # compute evaluation matrix\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        label_indices = tf.cast(labels, tf.int32)\n",
    "        accuracy = tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "        tf.summary.scalar('accuracy', accuracy[1]) # output to TensorBoard \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels,\n",
    "            logits=logits)\n",
    " \n",
    "    # define operations\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #global_step = tf.train.create_global_step()\n",
    "        #global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        global_step = tf.train.get_or_create_global_step()        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=FLAGS.learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)\n",
    "        # Ask for accuracy and loss in each steps ##### Modified\n",
    "        class _CustomLoggingHook(tf.train.SessionRunHook): ##### Modified\n",
    "            def begin(self): ##### Modified\n",
    "                self.training_accuracy = [] ##### Modified\n",
    "                self.training_loss = [] ##### Modified\n",
    "            def before_run(self, run_context): ##### Modified\n",
    "                return tf.train.SessionRunArgs([accuracy[1], loss, global_step]) ##### Modified\n",
    "            def after_run(self, run_context, run_values): ##### Modified\n",
    "                result_accuracy, result_loss, result_step = run_values.results ##### Modified\n",
    "                #run.log('training_accuracy', result_accuracy) ##### Modified\n",
    "                #run.log('training_loss', result_loss) ##### Modified\n",
    "                if result_step % 10 == 0 : ##### Modified\n",
    "                    self.training_accuracy.append(result_accuracy) ##### Modified\n",
    "                    self.training_loss.append(result_loss) ##### Modified\n",
    "                if result_step % 100 == 0 : # save logs in each 100 steps ##### Modified\n",
    "                    run.log_list('training_accuracy', self.training_accuracy) ##### Modified\n",
    "                    run.log_list('training_loss', self.training_loss) ##### Modified\n",
    "                    self.training_accuracy = [] ##### Modified\n",
    "                    self.training_loss = [] ##### Modified\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            training_chief_hooks=[_CustomLoggingHook()], ##### Modified\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "        predictions = {\n",
    "            'classes': predicted_indices,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            predictions=predictions,\n",
    "            export_outputs=export_outputs)\n",
    "\n",
    "def _my_serving_input_fn():\n",
    "    inputs = {'inputs': tf.placeholder(tf.float32, [None, 784])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "#\n",
    "# Main\n",
    "#\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data_folder',\n",
    "    type=str,\n",
    "    default='./data',\n",
    "    help='Folder path for input data')\n",
    "parser.add_argument(\n",
    "    '--chkpoint_folder',\n",
    "    type=str,\n",
    "    default='./logs',  # AML experiments logs folder\n",
    "    help='Folder path for checkpoint files')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./outputs',  # AML experiments outputs folder\n",
    "    help='Folder path for model output')\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default='0.07',\n",
    "    help='Learning Rate')\n",
    "parser.add_argument(\n",
    "    '--first_layer',\n",
    "    type=int,\n",
    "    default='128',\n",
    "    help='Neuron number for the first hidden layer')\n",
    "parser.add_argument(\n",
    "    '--second_layer',\n",
    "    type=int,\n",
    "    default='64',\n",
    "    help='Neuron number for the second hidden layer')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# clean checkpoint and model folder if exists\n",
    "if os.path.exists(FLAGS.chkpoint_folder) :\n",
    "    for file_name in os.listdir(FLAGS.chkpoint_folder):\n",
    "        file_path = os.path.join(FLAGS.chkpoint_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "if os.path.exists(FLAGS.model_folder) :\n",
    "    for file_name in os.listdir(FLAGS.model_folder):\n",
    "        file_path = os.path.join(FLAGS.model_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "# read TF_CONFIG\n",
    "run_config = tf.estimator.RunConfig()\n",
    "\n",
    "# create Estimator\n",
    "mnist_fullyconnected_classifier = tf.estimator.Estimator(\n",
    "    model_fn=_my_model_fn,\n",
    "    model_dir=FLAGS.chkpoint_folder,\n",
    "    config=run_config)\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'train.tfrecords'), 2),\n",
    "    max_steps=60000 * 2 / batch_size)\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
    "    steps=10000 * 1 / batch_size,\n",
    "    start_delay_secs=0)\n",
    "\n",
    "# run !\n",
    "eval_res = tf.estimator.train_and_evaluate(\n",
    "    mnist_fullyconnected_classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_dir = mnist_fullyconnected_classifier.export_savedmodel(\n",
    "    export_dir_base = FLAGS.model_folder,\n",
    "    serving_input_receiver_fn = _my_serving_input_fn)\n",
    "print('current working directory is ', os.getcwd())\n",
    "print('model is saved ', model_dir)\n",
    "\n",
    "# send logs to AML ##### Modified   \n",
    "run.log('learning_rate', FLAGS.learning_rate) ##### Modified\n",
    "run.log('1st_layer', FLAGS.first_layer) ##### Modified\n",
    "run.log('2nd_layer', FLAGS.second_layer) ##### Modified\n",
    "run.log('final_accuracy', eval_res[0]['accuracy']) ##### Modified\n",
    "run.log('final_loss', eval_res[0]['loss']) ##### Modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show logs using AML run history widget\n",
    "\n",
    "You can view detailed logs on \"Experiments\" in Azure Machine Learning studio UI (https://ml.azure.com/).\n",
    "\n",
    "You can also view your logs in your working notebook as follows. (For viewing in notebook, you must install extensions on your jupyter. See [Readme](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c03fdf52daa44aeae9cb312113439ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run_instance=run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot by code\n",
    "\n",
    "You can also explorer using python code and plot as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9c6347bf60>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "metrics = run.get_metrics()\n",
    "plt.plot(metrics['training_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
