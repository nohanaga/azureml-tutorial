{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise08 : Publish as a Web Service\n",
    "\n",
    "Finally we publish our model as a web service.\n",
    "\n",
    "Before running this code, complete the model training in \"[Exercise04 : Train on Remote GPU Virtual Machine](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/blob/master/notebooks/exercise04_train_remote.ipynb)\".\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get workspace settings\n",
    "\n",
    "Before starting, you must read your configuration settings. (See \"[Exercise01 : Prepare Config Settings](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/blob/master/notebooks/exercise01_prepare_config.ipynb)\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the registered model\n",
    "\n",
    "Get the trained model by MNIST dataset.<br>\n",
    "**Before running this code, complete the model training in \"[Exercise04 : Train on Remote GPU Virtual Machine](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/blob/master/notebooks/exercise04_train_remote.ipynb)\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "registered_model = Model(ws, 'mnist_model_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy as web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deploy as web service, first we generate the following scoring source.    \n",
    "This entry script in AML should include both ```init()``` and ```run()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global pred_fn\n",
    "    model_path = Model.get_model_path(model_name='mnist_model_test')\n",
    "    pred_fn = tf.contrib.predictor.from_saved_model(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "       data = json.loads(raw_data)['data']\n",
    "       result = pred_fn({'inputs': data})\n",
    "       return result['classes'].tolist()\n",
    "    except Exception as e:\n",
    "       result = str(e)\n",
    "       return 'Internal Exception : ' + result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create deploy configuration for preparation.<br>\n",
    "In this tutorial, we will deploy our serving in Azure Container Instance (ACI) with anonymous access permission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aci_conf = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=1,\n",
    "    memory_gb=1, \n",
    "    description='This is a tensorflow example.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create inference configuration for preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "# Generate conda dependency\n",
    "conda_dependency = CondaDependencies.create()\n",
    "conda_dependency.add_pip_package('tensorflow==1.15')\n",
    "### Or you can also write as follows (make sure to insert 'azureml-defaults' module)\n",
    "#conda_dependency = CondaDependencies.create(pip_packages=['azureml-defaults', 'tensorflow==1.15'])\n",
    "\n",
    "# Create environment and set the previous conda dependency\n",
    "myenv = Environment(name=\"myenv\")\n",
    "myenv.python.conda_dependencies = conda_dependency\n",
    "\n",
    "# Create inference config with score.py\n",
    "inf_conf = InferenceConfig(\n",
    "    entry_script=\"score.py\",\n",
    "    environment=myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, deploy as a web service !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-23 08:14:40+00:00 Creating Container Registry if not exists.\n",
      "2021-08-23 08:14:40+00:00 Registering the environment.\n",
      "2021-08-23 08:14:43+00:00 Building image..\n",
      "2021-08-23 08:22:42+00:00 Generating deployment configuration.\n",
      "2021-08-23 08:22:44+00:00 Submitting deployment to compute..\n",
      "2021-08-23 08:22:48+00:00 Checking the status of deployment my-mnist-service..\n",
      "2021-08-23 08:25:41+00:00 Checking the status of inference endpoint my-mnist-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "svc = Model.deploy(\n",
    "    name='my-mnist-service',\n",
    "    deployment_config=aci_conf,\n",
    "    models=[registered_model],\n",
    "    inference_config=inf_conf,\n",
    "    workspace=ws)\n",
    "svc.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-23T08:25:17,379725500+00:00 - iot-server/run \n",
      "2021-08-23T08:25:17,386434100+00:00 - rsyslog/run \n",
      "2021-08-23T08:25:17,395805700+00:00 - gunicorn/run \n",
      "Dynamic Python package installation is disabled.\n",
      "Starting HTTP server\n",
      "2021-08-23T08:25:17,398135200+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-08-23T08:25:17,764669100+00:00 - iot-server/finish 1 0\n",
      "2021-08-23T08:25:17,770766800+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (65)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 93\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-08-23 08:25:23,364 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2021-08-23 08:25:23,364 | root | INFO | Starting up request id generator\n",
      "2021-08-23 08:25:23,364 | root | INFO | Starting up app insight hooks\n",
      "2021-08-23 08:25:23,364 | root | INFO | Invoking user's init function\n",
      "\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "2021-08-23 08:25:24.420186: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_f2a613bfe61b2fc9ece8b47008c58af5/lib:/azureml-envs/azureml_f2a613bfe61b2fc9ece8b47008c58af5/lib:\n",
      "2021-08-23 08:25:24.420287: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-23 08:25:24.420321: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (SandboxHost-637653037711236532): /proc/driver/nvidia/version does not exist\n",
      "2021-08-23 08:25:24.420666: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-08-23 08:25:24.443225: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2095074999 Hz\n",
      "2021-08-23 08:25:24.443914: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dd35e30250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-23 08:25:24.444074: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "From /azureml-envs/azureml_f2a613bfe61b2fc9ece8b47008c58af5/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "Restoring parameters from azureml-models/mnist_model_test/1/1629700431/variables/variables\n",
      "2021-08-23 08:25:24,546 | root | INFO | Users's init has completed successfully\n",
      "2021-08-23 08:25:24,550 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-08-23 08:25:24,550 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-08-23 08:25:24,554 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-08-23 08:25:41,887 | root | INFO | Swagger file not present\n",
      "2021-08-23 08:25:41,887 | root | INFO | 404\n",
      "127.0.0.1 - - [23/Aug/2021:08:25:41 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-08-23 08:25:47,661 | root | INFO | Swagger file not present\n",
      "2021-08-23 08:25:47,662 | root | INFO | 404\n",
      "127.0.0.1 - - [23/Aug/2021:08:25:47 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See details, if error has occured\n",
    "print(svc.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check service url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://1582fdf0-bd82-4d2f-8212-39a25a810459.eastus.azurecontainer.io/score'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your web service\n",
    "\n",
    "Let's invoke your web service and check the returned results in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted :  [7, 2, 1]\n",
      "Actual    :  [7, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read data by tensor\n",
    "tfdata = tf.data.TFRecordDataset('./data/test.tfrecords')\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(tfdata)\n",
    "data_org = iterator.get_next()\n",
    "###\n",
    "data_exam = tf.parse_single_example(\n",
    "    data_org,\n",
    "    features={\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "data_image.set_shape([784])\n",
    "data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "\n",
    "# Run tensor and generate data\n",
    "with tf.Session() as sess:\n",
    "    image_arr = []\n",
    "    label_arr = []\n",
    "    for i in range(3):\n",
    "        image, label = sess.run([data_image, data_label])\n",
    "        image_arr.append(image.tolist())\n",
    "        label_arr.append(label)\n",
    "\n",
    "# Invoke web service !\n",
    "headers = {'Content-Type':'application/json'}\n",
    "# for AKS deployment (in production), provide service key in the header as below :\n",
    "# api_key1, api_key2 = svc.get_keys()\n",
    "# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key1)} \n",
    "values = json.dumps(image_arr)\n",
    "input_data = \"{\\\"data\\\": \" + values + \"}\"\n",
    "http_res = requests.post(\n",
    "    svc.scoring_uri,\n",
    "    input_data,\n",
    "    headers = headers)\n",
    "print('Predicted : ', http_res.text)\n",
    "print('Actual    : ', label_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
