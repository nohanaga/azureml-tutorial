{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02 : Prepare Data\n",
    "\n",
    "Here we learn ```Datastore``` and ```Dataset``` in Azure Machine Learning.<br>\n",
    "The subsequent all exercises (Exercise 04 -) will use data provisioned in this exercise, and you should then run this exercise beforehand.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get config setting\n",
    "\n",
    "Read your config settings. (See and run \"[Exercise01 : Prepare Config Settings](./exercise01_prepare_config.ipynb)\" beforehand.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use default datastore\n",
    "\n",
    "Azure Machine Learning (AML) workspace has its own default datastore. When you create an AML workspace, a storage account (default datastore) is automatically generated in the same resource group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get workspace default datastore\n",
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and register data as Dataset\n",
    "\n",
    "Now we create AML dataset and register in workspace.\n",
    "\n",
    "The data will be uploaded into the container in storage account, and you can share data in AML workspace.<br>\n",
    "Registering dataset is not mandatory, but you can trace versions of data with models or experiments by registering data as AML dataset. (You can see the registered dataset in AML studio UI.)\n",
    "\n",
    "In this exercise, I register all files in specific folders, but you can also register a part of files (such as, files with specific extension) as dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to tfdata\n",
      "Uploading an estimated of 2 files\n",
      "Uploading ./data/test.tfrecords\n",
      "Uploaded ./data/test.tfrecords, 1 files out of an estimated total of 2\n",
      "Uploading ./data/train.tfrecords\n",
      "Uploaded ./data/train.tfrecords, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n",
      "Creating new dataset\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "# Upload local \"data\" folder (incl. files) as \"tfdata\" folder\n",
    "mnist_dataset = Dataset.File.upload_directory(\n",
    "    src_dir='./data',\n",
    "    target=DataPath(ds, 'tfdata'),\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# Register dataset\n",
    "mnist_dataset = mnist_dataset.register(\n",
    "    workspace=ws,\n",
    "    name='mnist_tfrecords_dataset',\n",
    "    description='training and test dataset',\n",
    "    create_new_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Use datastore with your own provisioned storage\n",
    "\n",
    "(Running this tutorial is not needed for the following exercises, and you can skip.)\n",
    "\n",
    "Here we learn how to use your own blob storage as AML datastore.\n",
    "\n",
    "Before running, **please create Azure storage account and container as follows**.\n",
    "\n",
    "1. Create your Storage Account in [Azure Portal](https://portal.azure.com/).\n",
    "2. Create a container in storage account.\n",
    "3. Copy storage account name, access key, and container name.\n",
    "4. Set these values in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nds2 = Datastore.register_azure_blob_container(\\n    ws,\\n    datastore_name='myblob01',\\n    account_name='{STORAGE ACCOUNT NAME}',\\n    account_key='{ACCESS KEY}',\\n    container_name='{CONTAINER NAME}',\\n    overwrite=True)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "# Register your own storage as AML datastore\n",
    "ds2 = Datastore.register_azure_blob_container(\n",
    "    ws,\n",
    "    datastore_name='myblob01',\n",
    "    account_name='{STORAGE ACCOUNT NAME}',\n",
    "    account_key='{ACCESS KEY}',\n",
    "    container_name='{CONTAINER NAME}',\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have registered your own datastore, you can use this datastore with familiar API.<br>\n",
    "In this example, I upload local data. (See the uploaded data in your storage account.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to tfdata\n",
      "Uploading an estimated of 2 files\n",
      "Uploading ./data/test.tfrecords\n",
      "Uploaded ./data/test.tfrecords, 1 files out of an estimated total of 2\n",
      "Uploading ./data/train.tfrecords\n",
      "Uploaded ./data/train.tfrecords, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n",
      "Creating new dataset\n"
     ]
    }
   ],
   "source": [
    "# Get your own datastore\n",
    "ds2 = Datastore.get(ws, datastore_name='myblob01')\n",
    "\n",
    "# Upload local \"data\" folder (incl. files) as \"tfdata\" folder\n",
    "mnist_dataset2 = Dataset.File.upload_directory(\n",
    "    src_dir='./data',\n",
    "    target=DataPath(ds2, 'tfdata'),\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
